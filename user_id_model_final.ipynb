{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55f0920-6db8-46b3-82cb-72e0e28cb029",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de34370f-7e59-47c2-aa6f-69d76028d068",
   "metadata": {},
   "source": [
    "<h3>Importing important libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396c013b-8f0e-4016-9663-98b1ee70b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.stats import mode\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39203e0d-862a-484b-a346-e8a6e03dbfb8",
   "metadata": {},
   "source": [
    "<h3>Creating a Boxplot</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e48442c-f1f8-4f0e-b713-20e06d6de6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = '/public-datasets/liebers2022ijhci'\n",
    "tsv_files = sorted(\n",
    "    [f for f in os.listdir(input_directory) \n",
    "     if 'RescaleScene2H' in f and 'vr' in f and f.endswith('SESSION-1.tsv')]\n",
    ")\n",
    "\n",
    "input_file_path = os.path.join(input_directory, tsv_files[0])\n",
    "data = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "descriptive_stats = data.describe()\n",
    "#print(descriptive_stats)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.boxplot(data=data[data.columns[0:10]])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Boxplots of Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda0d9ed-1e51-4fde-8e2e-9ff336ca7cc8",
   "metadata": {},
   "source": [
    "<h3>Creating a spatial plot for head position</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea79caf-001b-4853-ac03-cc3a5b0ebb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(data['Unity.HeadPosition.position_x'], \n",
    "           data['Unity.HeadPosition.position_y'], \n",
    "           data['Unity.HeadPosition.position_z'], alpha=0.5)\n",
    "\n",
    "ax.scatter(data['Unity.HeadPosition.position_x'].iloc[0], \n",
    "           data['Unity.HeadPosition.position_y'].iloc[0], \n",
    "           data['Unity.HeadPosition.position_z'].iloc[0], color='red', s=100, label='Start')\n",
    "ax.scatter(data['Unity.HeadPosition.position_x'].iloc[25], \n",
    "           data['Unity.HeadPosition.position_y'].iloc[25], \n",
    "           data['Unity.HeadPosition.position_z'].iloc[25], color='purple', s=100, label='25-steps')\n",
    "ax.scatter(data['Unity.HeadPosition.position_x'].iloc[50], \n",
    "           data['Unity.HeadPosition.position_y'].iloc[50], \n",
    "           data['Unity.HeadPosition.position_z'].iloc[50], color='purple', s=100, label='50-steps')\n",
    "ax.scatter(data['Unity.HeadPosition.position_x'].iloc[100], \n",
    "           data['Unity.HeadPosition.position_y'].iloc[100], \n",
    "           data['Unity.HeadPosition.position_z'].iloc[100], color='purple', s=100, label='100-steps')\n",
    "ax.scatter(data['Unity.HeadPosition.position_x'].iloc[-1], \n",
    "           data['Unity.HeadPosition.position_y'].iloc[-1], \n",
    "           data['Unity.HeadPosition.position_z'].iloc[-1], color='green', s=100, label='End')\n",
    "\n",
    "ax.set_title('3D Spatial Plot of Head Position')\n",
    "ax.set_xlabel('Position X')\n",
    "ax.set_ylabel('Position Y')\n",
    "ax.set_zlabel('Position Z')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa76664-40db-489c-8864-379ce14e31f1",
   "metadata": {},
   "source": [
    "<h3>Defining the window slicing method</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2bd5940-a472-42a9-a038-99000fd2f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_slicing(data, window_size, step_size):\n",
    "    slices = []\n",
    "    num_windows = (len(data) - window_size) // step_size + 1\n",
    "    for start in range(0, len(data) - window_size + 1, step_size):\n",
    "        slices.append(data[start:start + window_size])\n",
    "    return np.array(slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a35e34-408e-4363-9159-b27dd8d9baac",
   "metadata": {},
   "source": [
    "<h3>Function to find the smallest dataframe in a list of data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8c84394-1694-4c33-81e4-ceb9561df988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min(data):\n",
    "    min = 1000000\n",
    "    for d in data:\n",
    "        if d['Unity.frameCount'].count() < min:\n",
    "            min = d['Unity.frameCount'].count()\n",
    "    return min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea6289-5ae9-4f35-95a4-5fda270b44d8",
   "metadata": {},
   "source": [
    "<h3>Datenvorbereitung</h3>\n",
    "<ul>\n",
    "<li><strong>Dateien laden:</strong> Liest TSV-Dateien, die mit dem angegebenen Verhaltensnamen und Suffix übereinstimmen.</li>\n",
    "<li><strong>Daten normalisieren:</strong> Normalisiert die Kopfpositionsdaten relativ zur Startposition.</li>\n",
    "<li><strong>Feature-Auswahl:</strong> Filtert relevante Spalten, die Positionen und Rotationen enthalten.</li>\n",
    "<li><strong>Daten bereinigen:</strong> Entfernt Zeilen mit fehlenden Werten.</li>\n",
    "<li><strong>Skalieren:</strong>Skaliert die Features mit 'StandardScaler'.</li>\n",
    "<li><strong>Fensterbildung:</strong> Teilt die Daten in überlappende Fenster für ein besseres Modelltraining.</li>\n",
    "<li><strong>Trainings- und Validierungssplit:</strong> Teilt die Daten in Trainings- und Validierungssets.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d5beddb-9e7b-4db8-88ef-d807396ea472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_noShuffle(X_train_scaled_slices,y_train_sliced):\n",
    "    np.random.seed(42)\n",
    "    test_size = 0.2\n",
    "    num_val_samples = int(test_size * len(X_train_scaled_slices))\n",
    "    val_indices = np.random.choice(len(X_train_scaled_slices), num_val_samples, replace=False)\n",
    "    val_mask = np.zeros(len(X_train_scaled_slices), dtype=bool)\n",
    "    val_mask[val_indices] = True\n",
    "    X_train_final = X_train_scaled_slices[~val_mask]\n",
    "    y_train_final = y_train_sliced[~val_mask]\n",
    "    X_val = X_train_scaled_slices[val_mask]\n",
    "    y_val = y_train_sliced[val_mask]\n",
    "    \n",
    "    return X_train_final,X_val,y_train_final,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b241bdc4-bc69-4522-b5d3-d36ddb26b125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_df(df, target_length):\n",
    "    current_length = len(df)\n",
    "    resampled_df = df.reset_index(drop=True).interpolate(method='linear')\n",
    "    resampled_df = resampled_df.reindex(np.linspace(0, current_length-1, target_length)).interpolate(method='linear').reset_index(drop=True)\n",
    "    return resampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "294d1e67-6e50-47c2-abea-cc9c33e56b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pid(file_name):\n",
    "    start_pos = file_name.find(\"PID-\") + len(\"PID-\")\n",
    "    end_pos = file_name.find(\"_\", start_pos)\n",
    "    return int(file_name[start_pos:end_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f90666f1-3e7d-440e-8942-9ee1bb5057ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_data(behavior_name,file_suffix):\n",
    "    # load Data\n",
    "    input_directory = '/public-datasets/liebers2022ijhci'\n",
    "    tsv_files = sorted([f for f in os.listdir(input_directory) \n",
    "                 if behavior_name in f and 'vr' in f and f.endswith(file_suffix)])\n",
    "\n",
    "    #tsv_files = sorted(tsv_files, key=extract_pid)\n",
    "    \n",
    "    X_train_list = []\n",
    "    y_train = []\n",
    "\n",
    "    # Verarbeite jede Datei, um Trainingsdaten und Labels zu extrahieren\n",
    "    for file_name in tsv_files:\n",
    "        pid_match = re.search(r'PID-(\\d+)', file_name)\n",
    "        pid_number = pid_match.group(1) if pid_match else None\n",
    "        \n",
    "        if pid_number:\n",
    "            \n",
    "            y_train.append(int(pid_number))\n",
    "        \n",
    "            input_file_path = os.path.join(input_directory, file_name)\n",
    "        \n",
    "            data = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "\n",
    "            # Normalisiere die Kopfpositionen relativ zum Startpunkt\n",
    "            data['Unity.HeadPosition.position_x'] -= data['Unity.HeadPosition.position_x'].iloc[0]\n",
    "            data['Unity.HeadPosition.position_y'] -= data['Unity.HeadPosition.position_y'].iloc[0]\n",
    "            data['Unity.HeadPosition.position_z'] -= data['Unity.HeadPosition.position_z'].iloc[0]\n",
    "            # Wandle die Positionen in absolute Werte um\n",
    "            data['Unity.HeadPosition.position_x'] = data['Unity.HeadPosition.position_x'].abs()\n",
    "            data['Unity.HeadPosition.position_y'] = data['Unity.HeadPosition.position_y'].abs()\n",
    "            data['Unity.HeadPosition.position_z'] = data['Unity.HeadPosition.position_z'].abs()\n",
    "            \n",
    "            \n",
    "            # Filtere relevante Spalten\n",
    "            filtered_columns = [\n",
    "                col for col in data.columns \n",
    "                if (('position' in col.lower() or 'rotation' in col.lower()) and \n",
    "                    'metacarpal' not in col.lower() and\n",
    "                    'gameobject' not in col.lower() and\n",
    "                    'quaternion' not in col.lower())\n",
    "            ]\n",
    "        \n",
    "            filtered_data = data[filtered_columns]\n",
    "            X_train_list.append(filtered_data)\n",
    "\n",
    "    # Kombiniere alle DataFrames in X_train_list zu einem einzigen DataFrame\n",
    "    X_train = pd.concat(X_train_list, ignore_index=True)\n",
    "    \n",
    "    # Erweitere die Zielvariablen entsprechend der Größe der Datenabschnitte\n",
    "    y_train_expanded = pd.Series(y_train).repeat([len(df) for df in X_train_list]).reset_index(drop=True)\n",
    "    # Kombiniere die Eingabedaten und die Zielvariablen in einem DataFrame\n",
    "    combined_df = X_train.copy()\n",
    "    combined_df['PID'] = y_train_expanded\n",
    "\n",
    "    # Entferne Zeilen mit fehlenden Werten\n",
    "    combined_df = combined_df.dropna()\n",
    "\n",
    "    # Trenne Eingabedaten und Zielvariablen\n",
    "    X_train_clean = combined_df.drop(columns=['PID'])\n",
    "    y_train_clean = combined_df['PID']\n",
    "\n",
    "    # One-Hot-Encoding der Zielvariablen\n",
    "    y_train_encoded = pd.get_dummies(y_train_clean, prefix='PID')\n",
    "\n",
    "    # Skaliere die Eingabedaten\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_clean)\n",
    "    \n",
    "    window_size = 30\n",
    "    step_size = 20\n",
    "\n",
    "    # Teile die Zielvariablen in Fenster\n",
    "    y_train_sliced = window_slicing(y_train_encoded.values, window_size, step_size)\n",
    "    # Nimm in jedem window die am häufigsten vorkommende label\n",
    "    y_train_sliced = mode(y_train_sliced, axis=1).mode[:, 0,:]\n",
    "\n",
    "    # Teile die skalierten Eingabedaten in Fenster\n",
    "    X_train_scaled_slices = window_slicing(X_train_scaled, window_size, step_size)\n",
    "\n",
    "    # Teile die Daten in Trainings- und Validierungsdatensätze auf\n",
    "    X_train_final, X_val, y_train_final, y_val = train_test_split(X_train_scaled_slices, y_train_sliced, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Konvertiere die Datentypen in float32\n",
    "    X_train_final = X_train_final.astype('float32')\n",
    "    X_val =X_val.astype('float32')\n",
    "    y_train_final = y_train_final.astype('float32')\n",
    "    y_val =y_val.astype('float32')\n",
    "    print(X_train_final.dtype)\n",
    "\n",
    "    print(f\"X_train_final shape: {X_train_final.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}\")\n",
    "    print(f\"y_train_final shape: {y_train_final.shape}\")\n",
    "    print(f\"y_val shape: {y_val.shape}\")\n",
    "\n",
    "    return X_train_final, X_val, y_train_final, y_val, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4ae8966-9e5f-4cc7-9897-7e56cc03f070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(behavior_name,file_suffix, scaler):\n",
    "    input_directory = '/public-datasets/liebers2022ijhci'\n",
    "    tsv_files = sorted([f for f in os.listdir(input_directory) \n",
    "                if behavior_name in f and 'vr' in f and f.endswith(file_suffix)])\n",
    "    \n",
    "    #tsv_files = sorted(tsv_files, key=extract_pid)\n",
    "    \n",
    "    X_test_list = []\n",
    "    y_test = []\n",
    "\n",
    "    for file_name in tsv_files:\n",
    "        pid_match = re.search(r'PID-(\\d+)', file_name)\n",
    "        pid_number = pid_match.group(1) if pid_match else None\n",
    "        \n",
    "        if pid_number:\n",
    "            \n",
    "            y_test.append(int(pid_number))\n",
    "            \n",
    "            input_file_path = os.path.join(input_directory, file_name)\n",
    "        \n",
    "            data = pd.read_csv(input_file_path, sep='\\t', low_memory=False)\n",
    "        \n",
    "            data['Unity.HeadPosition.position_x'] -= data['Unity.HeadPosition.position_x'].iloc[0]\n",
    "            data['Unity.HeadPosition.position_y'] -= data['Unity.HeadPosition.position_y'].iloc[0]\n",
    "            data['Unity.HeadPosition.position_z'] -= data['Unity.HeadPosition.position_z'].iloc[0]\n",
    "\n",
    "            data['Unity.HeadPosition.position_x'] = data['Unity.HeadPosition.position_x'].abs()\n",
    "            data['Unity.HeadPosition.position_y'] = data['Unity.HeadPosition.position_y'].abs()\n",
    "            data['Unity.HeadPosition.position_z'] = data['Unity.HeadPosition.position_z'].abs()\n",
    "            \n",
    "            # Filter columns\n",
    "            filtered_columns = [\n",
    "                col for col in data.columns \n",
    "                if (('position' in col.lower() or 'rotation' in col.lower()) and \n",
    "                    'metacarpal' not in col.lower() and\n",
    "                    'gameobject' not in col.lower() and\n",
    "                    'quaternion' not in col.lower())\n",
    "            ]\n",
    "            \n",
    "            filtered_data = data[filtered_columns]\n",
    "            X_test_list.append(filtered_data)\n",
    "\n",
    "    X_test = pd.concat(X_test_list, ignore_index=True)\n",
    "    \n",
    "    if behavior_name == 'ContextMenuScene2H':\n",
    "        # Find indices of 0s and 2s\n",
    "        zero_indices = [i for i, x in enumerate(y_test) if x == 0]\n",
    "        seven_indices = [i for i, x in enumerate(y_test) if x == 7]\n",
    "        \n",
    "        # Swap the values at these indices\n",
    "        for i in range(len(zero_indices)):\n",
    "            y_test[zero_indices[i]] = 7\n",
    "        for i in range(len(seven_indices)):\n",
    "            y_test[seven_indices[i]] = 0\n",
    "\n",
    "    y_test_expanded = pd.Series(y_test).repeat([len(df) for df in X_test_list]).reset_index(drop=True)\n",
    "\n",
    "    combined_df = X_test.copy()\n",
    "    combined_df['PID'] = y_test_expanded\n",
    "    combined_df = combined_df.dropna()\n",
    "   \n",
    "    X_test_clean = combined_df.drop(columns=['PID'])\n",
    "    y_test_clean = combined_df['PID']\n",
    "\n",
    "    y_test_encoded = pd.get_dummies(y_test_clean, prefix='PID')\n",
    "    \n",
    "    X_test_scaled = scaler.transform(X_test_clean)\n",
    "    \n",
    "    window_size = 30\n",
    "    step_size = 20\n",
    "    \n",
    "    X_test_scaled_slices = window_slicing(X_test_scaled, window_size, step_size)\n",
    "    y_test_sliced = window_slicing(y_test_encoded.values, window_size, step_size)\n",
    "    \n",
    "    y_test_sliced = mode(y_test_sliced, axis=1).mode[:, 0,:]\n",
    "    \n",
    "    X_test_final = X_test_scaled_slices.astype('float32')\n",
    "    y_test_final = y_test_sliced.astype('float32')\n",
    "\n",
    "    print(f\"X_test_final shape: {X_test_final.shape}\")\n",
    "    print(f\"y_test_final shape: {y_test_final.shape}\")\n",
    "    \n",
    "\n",
    "    return X_test_final, y_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34cecf28-eb98-4b6e-8f33-abfa2941a5ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "X_train_final shape: (4000, 30, 258)\n",
      "X_val shape: (1001, 30, 258)\n",
      "y_train_final shape: (4000, 16)\n",
      "y_val shape: (1001, 16)\n",
      "--------------------\n",
      "float32\n",
      "X_train_final shape: (2299, 30, 258)\n",
      "X_val shape: (575, 30, 258)\n",
      "y_train_final shape: (2299, 16)\n",
      "y_val shape: (575, 16)\n",
      "--------------------\n",
      "float32\n",
      "X_train_final shape: (10819, 30, 258)\n",
      "X_val shape: (2705, 30, 258)\n",
      "y_train_final shape: (10819, 16)\n",
      "y_val shape: (2705, 16)\n",
      "--------------------\n",
      "float32\n",
      "X_train_final shape: (3230, 30, 258)\n",
      "X_val shape: (808, 30, 258)\n",
      "y_train_final shape: (3230, 16)\n",
      "y_val shape: (808, 16)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "reposition_X_train, reposition_X_val,reposition_y_train, reposition_y_val, reposition_scaler = prepare_train_data('RepositionScene2H', 'SESSION-1.tsv')\n",
    "print('-' *20)\n",
    "contextmenu_X_train, contextmenu_X_val,contextmenu_y_train, contextmenu_y_val, contextmenu_scaler = prepare_train_data('ContextMenuScene2H', 'SESSION-1.tsv')\n",
    "print('-' *20)\n",
    "bikeyboard_X_train, bikeyboard_X_val,bikeyboard_y_train, bikeyboard_y_val, bikeyboard_scaler = prepare_train_data('KeyboardScene2H', 'SESSION-1.tsv')\n",
    "print('-' *20)\n",
    "rescale_X_train, rescale_X_val,rescale_y_train, rescale_y_val, rescale_scaler = prepare_train_data('RescaleScene2H', 'SESSION-1.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99d7e39b-e10a-4506-abfc-32e70d0e7366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_final shape: (3538, 30, 258)\n",
      "y_test_final shape: (3538, 16)\n",
      "--------------------\n",
      "X_test_final shape: (2838, 30, 258)\n",
      "y_test_final shape: (2838, 16)\n",
      "--------------------\n",
      "X_test_final shape: (10588, 30, 258)\n",
      "y_test_final shape: (10588, 16)\n",
      "--------------------\n",
      "X_test_final shape: (3203, 30, 258)\n",
      "y_test_final shape: (3203, 16)\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "reposition_X_test, reposition_y_test = prepare_test_data('RepositionScene2H', 'SESSION-2.tsv', reposition_scaler)\n",
    "print('-' *20)\n",
    "contextmenu_X_test, contextmenu_y_test = prepare_test_data('ContextMenuScene2H', 'SESSION-2.tsv', contextmenu_scaler)\n",
    "print('-' *20)\n",
    "bikeyboard_X_test, bikeyboard_y_test = prepare_test_data('KeyboardScene2H', 'SESSION-2.tsv', bikeyboard_scaler)\n",
    "print('-' *20)\n",
    "rescale_X_test, rescale_y_test = prepare_test_data('RescaleScene2H', 'SESSION-2.tsv', rescale_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "d52e15df-314a-4b70-b7fd-6d196bf73481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nan(X_train,X_val,X_test):\n",
    "    print('Check nan values in train and test data')\n",
    "    print(np.isnan(X_train).sum())\n",
    "    print(np.isnan(X_val).sum())\n",
    "    print(np.isnan(X_test).sum())\n",
    "    \n",
    "    print('Check inf values in train and test data')\n",
    "    print(np.isinf(X_train).sum())\n",
    "    print(np.isinf(X_val).sum())\n",
    "    print(np.isinf(X_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "07b9b51b-aa05-4099-bd41-59b3a198a2d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check nan values in train and test data\n",
      "0\n",
      "0\n",
      "0\n",
      "Check inf values in train and test data\n",
      "0\n",
      "0\n",
      "0\n",
      "Check nan values in train and test data\n",
      "0\n",
      "0\n",
      "0\n",
      "Check inf values in train and test data\n",
      "0\n",
      "0\n",
      "0\n",
      "Check nan values in train and test data\n",
      "0\n",
      "0\n",
      "0\n",
      "Check inf values in train and test data\n",
      "0\n",
      "0\n",
      "0\n",
      "Check nan values in train and test data\n",
      "0\n",
      "0\n",
      "0\n",
      "Check inf values in train and test data\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "check_for_nan(reposition_X_train,reposition_X_val,reposition_X_test)\n",
    "check_for_nan(contextmenu_X_train,contextmenu_X_val,contextmenu_X_test)\n",
    "check_for_nan(bikeyboard_X_train,bikeyboard_X_val,bikeyboard_X_test)\n",
    "check_for_nan(rescale_X_train,rescale_X_val,rescale_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37cb5696-013e-4bc6-ba6f-403897d0e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input,Dense, Dropout, Conv1D, MaxPooling1D, Flatten, LSTM, BatchNormalization,Bidirectional,Layer,GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3c1bea-afe8-4fec-bcff-925960df0936",
   "metadata": {},
   "source": [
    "<h4>Das erste Model:</h4>\n",
    "Input Layer <br>\n",
    "2 Hidden Dense Layer<br>\n",
    "Output Layer<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09a0daf6-b2b3-4d60-abd9-4c7a463427c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(input_shape), activation='relu', kernel_initializer=HeNormal()))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer=HeNormal()))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer=HeNormal()))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipvalue=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0ce49-2888-4939-b6a7-f4ea197bb69c",
   "metadata": {},
   "source": [
    "<h4>Das zweite Model:</h4>\n",
    "Input Layer <br>\n",
    "2 Hidden Conv1D Layer<br>\n",
    "1 Hidden LSTM Layer<br>\n",
    "Output Layer<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4318c2ad-08bf-4b79-97ba-46fc2728d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complex_model(input_shape, num_classes, learning_rate=0.0001):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        Dropout(0.3),\n",
    "        LSTM(50),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef958c3a-e8e4-4565-b5fc-9b281bb8ba5d",
   "metadata": {},
   "source": [
    "<h4>Das dritte Model:</h4>\n",
    "Input Layer <br>\n",
    "2 Hidden LSTM Layer<br>\n",
    "Output Layer<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8c97934-106b-45fc-995b-ba89f70edbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_complex_model2(input_shape, num_classes, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(LSTM(64, return_sequences=True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6899fa8-c6f1-4bb3-8af7-ab2143a68883",
   "metadata": {},
   "source": [
    "<h4>Das endgültige Model</h4>\n",
    "Input Layer  mit kernel regularizer<br>\n",
    "2 Hidden Conv1D Layer mit kernel regularizer<br>\n",
    "2 Hidden LSTM Layer  mit kernel regularizer<br>\n",
    "2 Hidden Dense Layer  mit kernel regularizer<br>\n",
    "Output Layer mit kernel regularizer<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43b5dbbc-9892-4869-a312-53a96c8ce527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_most_complex_model(input_shape, num_classes, learning_rate=0.0001):\n",
    "    model = Sequential([\n",
    "        Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        #Dropout(0.3),\n",
    "        \n",
    "        Conv1D(128, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        #Dropout(0.3),\n",
    "        \n",
    "        Conv1D(256, kernel_size=3, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        #Dropout(0.3),\n",
    "        \n",
    "        LSTM(100, return_sequences=True, kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.3),\n",
    "        \n",
    "        LSTM(100, kernel_regularizer=l2(0.01)),\n",
    "        #Dropout(0.3),\n",
    "        \n",
    "        Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        #Dropout(0.3),\n",
    "        \n",
    "        Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        #Dropout(0.3),\n",
    "        \n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb469ea1-880e-4cc2-bbbd-381b8c948695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(X_train,y_train):\n",
    "    input_shape = (X_train.shape[1],X_train.shape[2])\n",
    "    num_classes = y_train.shape[1]\n",
    "    model = create_most_complex_model(input_shape, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a0b7dd0b-8c20-4c25-99fc-eb9df914cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reposition_model = prepare_model(reposition_X_train,reposition_y_train)\n",
    "contextmenu_model = prepare_model(contextmenu_X_train,contextmenu_y_train)\n",
    "bikeyboard_model = prepare_model(bikeyboard_X_train,bikeyboard_y_train)\n",
    "rescale_model = prepare_model(rescale_X_train,rescale_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45018d4d-36e3-4ae0-a8ca-0d4242e94382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, y_train,X_val,y_val,epochs=100):\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        callbacks=[reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b2469cc-6af2-40b7-a3c3-5a082df5bc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_1 =0\n",
    "counter_2 =0\n",
    "counter_3 =0\n",
    "counter_4 =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f119577-b770-4685-afcb-1bdc453040be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epochs 200\n",
      "Epoch 1/200\n",
      "125/125 [==============================] - 5s 19ms/step - loss: 12.9751 - accuracy: 0.4880 - val_loss: 13.6590 - val_accuracy: 0.0430\n",
      "Epoch 2/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 11.3091 - accuracy: 0.7680 - val_loss: 12.7387 - val_accuracy: 0.0899\n",
      "Epoch 3/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 10.3114 - accuracy: 0.8480 - val_loss: 11.3709 - val_accuracy: 0.3526\n",
      "Epoch 4/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 9.4863 - accuracy: 0.8960 - val_loss: 9.8233 - val_accuracy: 0.7962\n",
      "Epoch 5/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 8.7389 - accuracy: 0.9250 - val_loss: 8.6413 - val_accuracy: 0.8961\n",
      "Epoch 6/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 8.0773 - accuracy: 0.9457 - val_loss: 7.8891 - val_accuracy: 0.9201\n",
      "Epoch 7/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 7.4385 - accuracy: 0.9607 - val_loss: 7.2656 - val_accuracy: 0.9201\n",
      "Epoch 8/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 6.8780 - accuracy: 0.9635 - val_loss: 6.7214 - val_accuracy: 0.9321\n",
      "Epoch 9/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 6.3549 - accuracy: 0.9755 - val_loss: 6.2468 - val_accuracy: 0.9391\n",
      "Epoch 10/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 5.8952 - accuracy: 0.9747 - val_loss: 5.8072 - val_accuracy: 0.9361\n",
      "Epoch 11/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 5.4456 - accuracy: 0.9797 - val_loss: 5.3639 - val_accuracy: 0.9421\n",
      "Epoch 12/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 5.0288 - accuracy: 0.9837 - val_loss: 4.9583 - val_accuracy: 0.9361\n",
      "Epoch 13/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 4.6228 - accuracy: 0.9868 - val_loss: 4.5544 - val_accuracy: 0.9491\n",
      "Epoch 14/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 4.2672 - accuracy: 0.9870 - val_loss: 4.2176 - val_accuracy: 0.9421\n",
      "Epoch 15/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 3.9566 - accuracy: 0.9850 - val_loss: 3.9299 - val_accuracy: 0.9411\n",
      "Epoch 16/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 3.6369 - accuracy: 0.9883 - val_loss: 3.6069 - val_accuracy: 0.9540\n",
      "Epoch 17/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 3.3453 - accuracy: 0.9902 - val_loss: 3.3255 - val_accuracy: 0.9461\n",
      "Epoch 18/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 3.0788 - accuracy: 0.9898 - val_loss: 3.0775 - val_accuracy: 0.9500\n",
      "Epoch 19/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.8497 - accuracy: 0.9893 - val_loss: 2.8838 - val_accuracy: 0.9421\n",
      "Epoch 20/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.6338 - accuracy: 0.9902 - val_loss: 2.6519 - val_accuracy: 0.9540\n",
      "Epoch 21/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.4415 - accuracy: 0.9900 - val_loss: 2.4858 - val_accuracy: 0.9550\n",
      "Epoch 22/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.2678 - accuracy: 0.9895 - val_loss: 2.3019 - val_accuracy: 0.9560\n",
      "Epoch 23/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 2.0832 - accuracy: 0.9925 - val_loss: 2.1319 - val_accuracy: 0.9560\n",
      "Epoch 24/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.9245 - accuracy: 0.9920 - val_loss: 1.9698 - val_accuracy: 0.9471\n",
      "Epoch 25/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.7902 - accuracy: 0.9910 - val_loss: 1.8482 - val_accuracy: 0.9550\n",
      "Epoch 26/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.6614 - accuracy: 0.9915 - val_loss: 1.7306 - val_accuracy: 0.9570\n",
      "Epoch 27/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.5471 - accuracy: 0.9880 - val_loss: 1.6297 - val_accuracy: 0.9431\n",
      "Epoch 28/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.4342 - accuracy: 0.9908 - val_loss: 1.5055 - val_accuracy: 0.9530\n",
      "Epoch 29/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.3405 - accuracy: 0.9905 - val_loss: 1.4177 - val_accuracy: 0.9560\n",
      "Epoch 30/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.2384 - accuracy: 0.9915 - val_loss: 1.3206 - val_accuracy: 0.9550\n",
      "Epoch 31/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 1.1610 - accuracy: 0.9908 - val_loss: 1.2323 - val_accuracy: 0.9580\n",
      "Epoch 32/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0846 - accuracy: 0.9890 - val_loss: 1.1546 - val_accuracy: 0.9580\n",
      "Epoch 33/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 1.0189 - accuracy: 0.9902 - val_loss: 1.0788 - val_accuracy: 0.9620\n",
      "Epoch 34/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.9378 - accuracy: 0.9937 - val_loss: 1.0064 - val_accuracy: 0.9670\n",
      "Epoch 35/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.8816 - accuracy: 0.9902 - val_loss: 0.9445 - val_accuracy: 0.9690\n",
      "Epoch 36/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.8266 - accuracy: 0.9902 - val_loss: 0.9000 - val_accuracy: 0.9650\n",
      "Epoch 37/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.7784 - accuracy: 0.9908 - val_loss: 0.8553 - val_accuracy: 0.9660\n",
      "Epoch 38/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.7376 - accuracy: 0.9893 - val_loss: 0.8293 - val_accuracy: 0.9580\n",
      "Epoch 39/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6926 - accuracy: 0.9898 - val_loss: 0.7836 - val_accuracy: 0.9600\n",
      "Epoch 40/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6514 - accuracy: 0.9912 - val_loss: 0.7513 - val_accuracy: 0.9590\n",
      "Epoch 41/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.6224 - accuracy: 0.9883 - val_loss: 0.7094 - val_accuracy: 0.9540\n",
      "Epoch 42/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5834 - accuracy: 0.9915 - val_loss: 0.6754 - val_accuracy: 0.9600\n",
      "Epoch 43/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5539 - accuracy: 0.9900 - val_loss: 0.6652 - val_accuracy: 0.9530\n",
      "Epoch 44/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.5125 - accuracy: 0.9935 - val_loss: 0.6133 - val_accuracy: 0.9660\n",
      "Epoch 45/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4886 - accuracy: 0.9908 - val_loss: 0.5785 - val_accuracy: 0.9650\n",
      "Epoch 46/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4649 - accuracy: 0.9918 - val_loss: 0.5384 - val_accuracy: 0.9700\n",
      "Epoch 47/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4368 - accuracy: 0.9923 - val_loss: 0.5323 - val_accuracy: 0.9590\n",
      "Epoch 48/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.4211 - accuracy: 0.9893 - val_loss: 0.4839 - val_accuracy: 0.9700\n",
      "Epoch 49/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.4013 - accuracy: 0.9902 - val_loss: 0.4639 - val_accuracy: 0.9680\n",
      "Epoch 50/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3746 - accuracy: 0.9927 - val_loss: 0.4333 - val_accuracy: 0.9710\n",
      "Epoch 51/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3725 - accuracy: 0.9893 - val_loss: 0.4504 - val_accuracy: 0.9640\n",
      "Epoch 52/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3417 - accuracy: 0.9915 - val_loss: 0.4227 - val_accuracy: 0.9670\n",
      "Epoch 53/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3364 - accuracy: 0.9905 - val_loss: 0.4293 - val_accuracy: 0.9620\n",
      "Epoch 54/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3170 - accuracy: 0.9908 - val_loss: 0.3885 - val_accuracy: 0.9710\n",
      "Epoch 55/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.3002 - accuracy: 0.9927 - val_loss: 0.3911 - val_accuracy: 0.9650\n",
      "Epoch 56/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2891 - accuracy: 0.9912 - val_loss: 0.4008 - val_accuracy: 0.9560\n",
      "Epoch 57/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2941 - accuracy: 0.9865 - val_loss: 0.3645 - val_accuracy: 0.9710\n",
      "Epoch 58/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2782 - accuracy: 0.9890 - val_loss: 0.3727 - val_accuracy: 0.9650\n",
      "Epoch 59/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2569 - accuracy: 0.9930 - val_loss: 0.3546 - val_accuracy: 0.9610\n",
      "Epoch 60/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.2615 - accuracy: 0.9862 - val_loss: 0.3379 - val_accuracy: 0.9640\n",
      "Epoch 61/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2414 - accuracy: 0.9918 - val_loss: 0.3201 - val_accuracy: 0.9710\n",
      "Epoch 62/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2363 - accuracy: 0.9912 - val_loss: 0.3527 - val_accuracy: 0.9560\n",
      "Epoch 63/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2238 - accuracy: 0.9923 - val_loss: 0.3521 - val_accuracy: 0.9580\n",
      "Epoch 64/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2254 - accuracy: 0.9910 - val_loss: 0.3047 - val_accuracy: 0.9680\n",
      "Epoch 65/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2124 - accuracy: 0.9920 - val_loss: 0.3206 - val_accuracy: 0.9620\n",
      "Epoch 66/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2054 - accuracy: 0.9927 - val_loss: 0.2594 - val_accuracy: 0.9760\n",
      "Epoch 67/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.2001 - accuracy: 0.9920 - val_loss: 0.2782 - val_accuracy: 0.9710\n",
      "Epoch 68/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1927 - accuracy: 0.9918 - val_loss: 0.3001 - val_accuracy: 0.9600\n",
      "Epoch 69/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1927 - accuracy: 0.9927 - val_loss: 0.2714 - val_accuracy: 0.9620\n",
      "Epoch 70/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1880 - accuracy: 0.9900 - val_loss: 0.2645 - val_accuracy: 0.9740\n",
      "Epoch 71/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1785 - accuracy: 0.9927 - val_loss: 0.2647 - val_accuracy: 0.9690\n",
      "Epoch 72/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1603 - accuracy: 0.9960 - val_loss: 0.2231 - val_accuracy: 0.9770\n",
      "Epoch 73/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1469 - accuracy: 0.9998 - val_loss: 0.2227 - val_accuracy: 0.9780\n",
      "Epoch 74/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1439 - accuracy: 1.0000 - val_loss: 0.2148 - val_accuracy: 0.9770\n",
      "Epoch 75/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1403 - accuracy: 1.0000 - val_loss: 0.2119 - val_accuracy: 0.9780\n",
      "Epoch 76/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1378 - accuracy: 0.9998 - val_loss: 0.2048 - val_accuracy: 0.9780\n",
      "Epoch 77/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1342 - accuracy: 1.0000 - val_loss: 0.2022 - val_accuracy: 0.9790\n",
      "Epoch 78/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1330 - accuracy: 0.9998 - val_loss: 0.2008 - val_accuracy: 0.9760\n",
      "Epoch 79/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1286 - accuracy: 0.9998 - val_loss: 0.1950 - val_accuracy: 0.9780\n",
      "Epoch 80/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1256 - accuracy: 1.0000 - val_loss: 0.1940 - val_accuracy: 0.9770\n",
      "Epoch 81/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1238 - accuracy: 0.9992 - val_loss: 0.1888 - val_accuracy: 0.9780\n",
      "Epoch 82/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1211 - accuracy: 1.0000 - val_loss: 0.1798 - val_accuracy: 0.9800\n",
      "Epoch 83/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1177 - accuracy: 0.9998 - val_loss: 0.1798 - val_accuracy: 0.9790\n",
      "Epoch 84/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1157 - accuracy: 0.9998 - val_loss: 0.1739 - val_accuracy: 0.9810\n",
      "Epoch 85/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 0.1716 - val_accuracy: 0.9800\n",
      "Epoch 86/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1100 - accuracy: 0.9998 - val_loss: 0.1618 - val_accuracy: 0.9800\n",
      "Epoch 87/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1075 - accuracy: 1.0000 - val_loss: 0.1652 - val_accuracy: 0.9780\n",
      "Epoch 88/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.1784 - val_accuracy: 0.9780\n",
      "Epoch 89/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1028 - accuracy: 1.0000 - val_loss: 0.1563 - val_accuracy: 0.9810\n",
      "Epoch 90/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 0.1593 - val_accuracy: 0.9820\n",
      "Epoch 91/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0983 - accuracy: 1.0000 - val_loss: 0.1479 - val_accuracy: 0.9810\n",
      "Epoch 92/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0972 - accuracy: 0.9998 - val_loss: 0.1562 - val_accuracy: 0.9760\n",
      "Epoch 93/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0948 - accuracy: 0.9998 - val_loss: 0.1528 - val_accuracy: 0.9810\n",
      "Epoch 94/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0935 - accuracy: 0.9995 - val_loss: 0.1619 - val_accuracy: 0.9790\n",
      "Epoch 95/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.1469 - val_accuracy: 0.9840\n",
      "Epoch 96/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0888 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9820\n",
      "Epoch 97/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0870 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9810\n",
      "Epoch 98/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0856 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9820\n",
      "Epoch 99/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0835 - accuracy: 0.9998 - val_loss: 0.1324 - val_accuracy: 0.9830\n",
      "Epoch 100/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0822 - accuracy: 1.0000 - val_loss: 0.1329 - val_accuracy: 0.9800\n",
      "Epoch 101/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0815 - accuracy: 0.9998 - val_loss: 0.1377 - val_accuracy: 0.9790\n",
      "Epoch 102/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0799 - accuracy: 0.9995 - val_loss: 0.1299 - val_accuracy: 0.9850\n",
      "Epoch 103/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1251 - val_accuracy: 0.9830\n",
      "Epoch 104/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0771 - accuracy: 1.0000 - val_loss: 0.1300 - val_accuracy: 0.9850\n",
      "Epoch 105/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0755 - accuracy: 0.9995 - val_loss: 0.1310 - val_accuracy: 0.9850\n",
      "Epoch 106/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0738 - accuracy: 0.9998 - val_loss: 0.1215 - val_accuracy: 0.9830\n",
      "Epoch 107/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0729 - accuracy: 0.9998 - val_loss: 0.1285 - val_accuracy: 0.9830\n",
      "Epoch 108/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0724 - accuracy: 0.9995 - val_loss: 0.1307 - val_accuracy: 0.9810\n",
      "Epoch 109/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9830\n",
      "Epoch 110/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0695 - accuracy: 0.9998 - val_loss: 0.1279 - val_accuracy: 0.9790\n",
      "Epoch 111/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.1230 - val_accuracy: 0.9820\n",
      "Epoch 112/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0666 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9860\n",
      "Epoch 113/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0658 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9850\n",
      "Epoch 114/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0653 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9860\n",
      "Epoch 115/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0649 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9850\n",
      "Epoch 116/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0652 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9860\n",
      "Epoch 117/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0646 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9830\n",
      "Epoch 118/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9850\n",
      "Epoch 119/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9860\n",
      "Epoch 120/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0636 - accuracy: 0.9998 - val_loss: 0.1123 - val_accuracy: 0.9860\n",
      "Epoch 121/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0631 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9840\n",
      "Epoch 122/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9850\n",
      "Epoch 123/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.1102 - val_accuracy: 0.9840\n",
      "Epoch 124/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0623 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9850\n",
      "Epoch 125/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0618 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9840\n",
      "Epoch 126/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9830\n",
      "Epoch 127/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9840\n",
      "Epoch 128/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9860\n",
      "Epoch 129/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0605 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9860\n",
      "Epoch 130/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0606 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9870\n",
      "Epoch 131/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0612 - accuracy: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9860\n",
      "Epoch 132/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9850\n",
      "Epoch 133/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9860\n",
      "Epoch 134/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9860\n",
      "Epoch 135/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9860\n",
      "Epoch 136/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9860\n",
      "Epoch 137/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9860\n",
      "Epoch 138/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9860\n",
      "Epoch 139/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9850\n",
      "Epoch 140/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9860\n",
      "Epoch 141/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9840\n",
      "Epoch 142/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9840\n",
      "Epoch 143/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9860\n",
      "Epoch 144/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0593 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9860\n",
      "Epoch 145/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9860\n",
      "Epoch 146/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9860\n",
      "Epoch 147/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9860\n",
      "Epoch 148/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9840\n",
      "Epoch 149/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9850\n",
      "Epoch 150/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9850\n",
      "Epoch 151/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9840\n",
      "Epoch 152/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9860\n",
      "Epoch 153/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9850\n",
      "Epoch 154/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9840\n",
      "Epoch 155/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0587 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9850\n",
      "Epoch 156/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9850\n",
      "Epoch 157/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0587 - accuracy: 0.9998 - val_loss: 0.1081 - val_accuracy: 0.9840\n",
      "Epoch 158/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9840\n",
      "Epoch 159/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0582 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9840\n",
      "Epoch 160/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9830\n",
      "Epoch 161/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9850\n",
      "Epoch 162/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9850\n",
      "Epoch 163/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9850\n",
      "Epoch 164/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9840\n",
      "Epoch 165/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9850\n",
      "Epoch 166/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9860\n",
      "Epoch 167/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 0.9840\n",
      "Epoch 168/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9860\n",
      "Epoch 169/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9860\n",
      "Epoch 170/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0572 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9860\n",
      "Epoch 171/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9860\n",
      "Epoch 172/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9850\n",
      "Epoch 173/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9860\n",
      "Epoch 174/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9850\n",
      "Epoch 175/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9840\n",
      "Epoch 176/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9860\n",
      "Epoch 177/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9860\n",
      "Epoch 178/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9860\n",
      "Epoch 179/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9840\n",
      "Epoch 180/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9840\n",
      "Epoch 181/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.1054 - val_accuracy: 0.9860\n",
      "Epoch 182/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9850\n",
      "Epoch 183/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9840\n",
      "Epoch 184/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9840\n",
      "Epoch 185/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.1060 - val_accuracy: 0.9830\n",
      "Epoch 186/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9830\n",
      "Epoch 187/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9820\n",
      "Epoch 188/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9840\n",
      "Epoch 189/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.1065 - val_accuracy: 0.9850\n",
      "Epoch 190/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9840\n",
      "Epoch 191/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9850\n",
      "Epoch 192/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9840\n",
      "Epoch 193/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9830\n",
      "Epoch 194/200\n",
      "125/125 [==============================] - 2s 14ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.1058 - val_accuracy: 0.9840\n",
      "Epoch 195/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9840\n",
      "Epoch 196/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.1050 - val_accuracy: 0.9840\n",
      "Epoch 197/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9850\n",
      "Epoch 198/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9850\n",
      "Epoch 199/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9830\n",
      "Epoch 200/200\n",
      "125/125 [==============================] - 2s 15ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "counter_1 +=200\n",
    "print('current_epochs',counter_1)\n",
    "reposition_model = fit_model(reposition_model,reposition_X_train,reposition_y_train,reposition_X_val,reposition_y_val,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db1fe6ec-197a-47f7-9a0b-50c4f61ed90a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epochs 200\n",
      "Epoch 1/200\n",
      "72/72 [==============================] - 4s 18ms/step - loss: 13.3932 - accuracy: 0.3815 - val_loss: 13.8864 - val_accuracy: 0.0852\n",
      "Epoch 2/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 11.9482 - accuracy: 0.7177 - val_loss: 13.4079 - val_accuracy: 0.1130\n",
      "Epoch 3/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 11.1210 - accuracy: 0.8286 - val_loss: 12.7666 - val_accuracy: 0.1983\n",
      "Epoch 4/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 10.4371 - accuracy: 0.9013 - val_loss: 11.9906 - val_accuracy: 0.3617\n",
      "Epoch 5/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.8352 - accuracy: 0.9369 - val_loss: 11.0582 - val_accuracy: 0.6452\n",
      "Epoch 6/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 9.2566 - accuracy: 0.9539 - val_loss: 10.0201 - val_accuracy: 0.8783\n",
      "Epoch 7/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.7092 - accuracy: 0.9682 - val_loss: 9.0644 - val_accuracy: 0.9235\n",
      "Epoch 8/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 8.1967 - accuracy: 0.9761 - val_loss: 8.2715 - val_accuracy: 0.9478\n",
      "Epoch 9/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 7.6871 - accuracy: 0.9852 - val_loss: 7.6295 - val_accuracy: 0.9583\n",
      "Epoch 10/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 7.1985 - accuracy: 0.9917 - val_loss: 7.1028 - val_accuracy: 0.9548\n",
      "Epoch 11/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.7379 - accuracy: 0.9909 - val_loss: 6.6273 - val_accuracy: 0.9583\n",
      "Epoch 12/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 6.3055 - accuracy: 0.9930 - val_loss: 6.2044 - val_accuracy: 0.9600\n",
      "Epoch 13/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.8950 - accuracy: 0.9930 - val_loss: 5.7937 - val_accuracy: 0.9704\n",
      "Epoch 14/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 5.5262 - accuracy: 0.9935 - val_loss: 5.4294 - val_accuracy: 0.9670\n",
      "Epoch 15/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 5.1791 - accuracy: 0.9943 - val_loss: 5.1099 - val_accuracy: 0.9635\n",
      "Epoch 16/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 4.8485 - accuracy: 0.9948 - val_loss: 4.7731 - val_accuracy: 0.9670\n",
      "Epoch 17/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.5376 - accuracy: 0.9948 - val_loss: 4.4735 - val_accuracy: 0.9687\n",
      "Epoch 18/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 4.2566 - accuracy: 0.9943 - val_loss: 4.2098 - val_accuracy: 0.9704\n",
      "Epoch 19/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.9891 - accuracy: 0.9935 - val_loss: 3.9388 - val_accuracy: 0.9739\n",
      "Epoch 20/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.7251 - accuracy: 0.9965 - val_loss: 3.6677 - val_accuracy: 0.9791\n",
      "Epoch 21/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.4696 - accuracy: 0.9987 - val_loss: 3.4532 - val_accuracy: 0.9670\n",
      "Epoch 22/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 3.2473 - accuracy: 0.9965 - val_loss: 3.2355 - val_accuracy: 0.9583\n",
      "Epoch 23/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 3.0376 - accuracy: 0.9970 - val_loss: 3.0209 - val_accuracy: 0.9722\n",
      "Epoch 24/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.8307 - accuracy: 0.9974 - val_loss: 2.8227 - val_accuracy: 0.9687\n",
      "Epoch 25/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.6504 - accuracy: 0.9943 - val_loss: 2.6383 - val_accuracy: 0.9739\n",
      "Epoch 26/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 2.4865 - accuracy: 0.9970 - val_loss: 2.4954 - val_accuracy: 0.9635\n",
      "Epoch 27/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.3210 - accuracy: 0.9970 - val_loss: 2.3115 - val_accuracy: 0.9757\n",
      "Epoch 28/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.1761 - accuracy: 0.9948 - val_loss: 2.2193 - val_accuracy: 0.9687\n",
      "Epoch 29/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 2.0383 - accuracy: 0.9948 - val_loss: 2.0602 - val_accuracy: 0.9687\n",
      "Epoch 30/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.9104 - accuracy: 0.9978 - val_loss: 1.9389 - val_accuracy: 0.9687\n",
      "Epoch 31/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 1.7994 - accuracy: 0.9948 - val_loss: 1.8380 - val_accuracy: 0.9704\n",
      "Epoch 32/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.6859 - accuracy: 0.9961 - val_loss: 1.7184 - val_accuracy: 0.9722\n",
      "Epoch 33/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.5870 - accuracy: 0.9930 - val_loss: 1.6008 - val_accuracy: 0.9757\n",
      "Epoch 34/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.4835 - accuracy: 0.9970 - val_loss: 1.5025 - val_accuracy: 0.9722\n",
      "Epoch 35/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.3932 - accuracy: 0.9952 - val_loss: 1.4152 - val_accuracy: 0.9704\n",
      "Epoch 36/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.3029 - accuracy: 0.9978 - val_loss: 1.3439 - val_accuracy: 0.9687\n",
      "Epoch 37/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.2319 - accuracy: 0.9952 - val_loss: 1.3173 - val_accuracy: 0.9600\n",
      "Epoch 38/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.1555 - accuracy: 0.9970 - val_loss: 1.1984 - val_accuracy: 0.9774\n",
      "Epoch 39/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0903 - accuracy: 0.9957 - val_loss: 1.1312 - val_accuracy: 0.9670\n",
      "Epoch 40/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 1.0338 - accuracy: 0.9935 - val_loss: 1.0662 - val_accuracy: 0.9687\n",
      "Epoch 41/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.9650 - accuracy: 0.9983 - val_loss: 1.0332 - val_accuracy: 0.9739\n",
      "Epoch 42/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.9147 - accuracy: 0.9952 - val_loss: 0.9342 - val_accuracy: 0.9774\n",
      "Epoch 43/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.8696 - accuracy: 0.9935 - val_loss: 0.8967 - val_accuracy: 0.9791\n",
      "Epoch 44/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.8221 - accuracy: 0.9952 - val_loss: 0.8532 - val_accuracy: 0.9722\n",
      "Epoch 45/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.7805 - accuracy: 0.9939 - val_loss: 0.8157 - val_accuracy: 0.9757\n",
      "Epoch 46/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.7310 - accuracy: 0.9970 - val_loss: 0.7880 - val_accuracy: 0.9670\n",
      "Epoch 47/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.6869 - accuracy: 0.9987 - val_loss: 0.7589 - val_accuracy: 0.9652\n",
      "Epoch 48/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.6703 - accuracy: 0.9926 - val_loss: 0.7009 - val_accuracy: 0.9722\n",
      "Epoch 49/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.6164 - accuracy: 0.9970 - val_loss: 0.6884 - val_accuracy: 0.9687\n",
      "Epoch 50/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.5829 - accuracy: 0.9965 - val_loss: 0.6257 - val_accuracy: 0.9757\n",
      "Epoch 51/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.5427 - accuracy: 0.9978 - val_loss: 0.6149 - val_accuracy: 0.9704\n",
      "Epoch 52/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.5144 - accuracy: 0.9983 - val_loss: 0.5558 - val_accuracy: 0.9704\n",
      "Epoch 53/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.4915 - accuracy: 0.9957 - val_loss: 0.5568 - val_accuracy: 0.9687\n",
      "Epoch 54/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.4747 - accuracy: 0.9943 - val_loss: 0.5279 - val_accuracy: 0.9774\n",
      "Epoch 55/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.4532 - accuracy: 0.9939 - val_loss: 0.5272 - val_accuracy: 0.9670\n",
      "Epoch 56/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.4299 - accuracy: 0.9943 - val_loss: 0.4744 - val_accuracy: 0.9774\n",
      "Epoch 57/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.4070 - accuracy: 0.9974 - val_loss: 0.4741 - val_accuracy: 0.9687\n",
      "Epoch 58/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.3952 - accuracy: 0.9922 - val_loss: 0.4186 - val_accuracy: 0.9826\n",
      "Epoch 59/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.3712 - accuracy: 0.9961 - val_loss: 0.4176 - val_accuracy: 0.9774\n",
      "Epoch 60/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.3450 - accuracy: 0.9978 - val_loss: 0.4042 - val_accuracy: 0.9774\n",
      "Epoch 61/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.3321 - accuracy: 0.9970 - val_loss: 0.3685 - val_accuracy: 0.9809\n",
      "Epoch 62/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.3237 - accuracy: 0.9939 - val_loss: 0.3731 - val_accuracy: 0.9774\n",
      "Epoch 63/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.3033 - accuracy: 0.9965 - val_loss: 0.3573 - val_accuracy: 0.9757\n",
      "Epoch 64/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.2902 - accuracy: 0.9974 - val_loss: 0.3608 - val_accuracy: 0.9739\n",
      "Epoch 65/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.2790 - accuracy: 0.9974 - val_loss: 0.3705 - val_accuracy: 0.9704\n",
      "Epoch 66/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.2796 - accuracy: 0.9926 - val_loss: 0.3244 - val_accuracy: 0.9722\n",
      "Epoch 67/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.2641 - accuracy: 0.9948 - val_loss: 0.3050 - val_accuracy: 0.9791\n",
      "Epoch 68/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.2537 - accuracy: 0.9939 - val_loss: 0.2987 - val_accuracy: 0.9739\n",
      "Epoch 69/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.2442 - accuracy: 0.9939 - val_loss: 0.2911 - val_accuracy: 0.9704\n",
      "Epoch 70/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.2308 - accuracy: 0.9965 - val_loss: 0.2636 - val_accuracy: 0.9809\n",
      "Epoch 71/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.2286 - accuracy: 0.9926 - val_loss: 0.2710 - val_accuracy: 0.9722\n",
      "Epoch 72/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.2250 - accuracy: 0.9943 - val_loss: 0.2689 - val_accuracy: 0.9757\n",
      "Epoch 73/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.2122 - accuracy: 0.9939 - val_loss: 0.2531 - val_accuracy: 0.9809\n",
      "Epoch 74/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.2129 - accuracy: 0.9943 - val_loss: 0.3427 - val_accuracy: 0.9548\n",
      "Epoch 75/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.2286 - accuracy: 0.9874 - val_loss: 0.2416 - val_accuracy: 0.9757\n",
      "Epoch 76/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1938 - accuracy: 0.9965 - val_loss: 0.2193 - val_accuracy: 0.9843\n",
      "Epoch 77/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1909 - accuracy: 0.9943 - val_loss: 0.2498 - val_accuracy: 0.9809\n",
      "Epoch 78/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1839 - accuracy: 0.9952 - val_loss: 0.2250 - val_accuracy: 0.9722\n",
      "Epoch 79/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1712 - accuracy: 0.9983 - val_loss: 0.2238 - val_accuracy: 0.9757\n",
      "Epoch 80/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1644 - accuracy: 0.9983 - val_loss: 0.2197 - val_accuracy: 0.9791\n",
      "Epoch 81/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1650 - accuracy: 0.9957 - val_loss: 0.2013 - val_accuracy: 0.9809\n",
      "Epoch 82/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1600 - accuracy: 0.9948 - val_loss: 0.1757 - val_accuracy: 0.9843\n",
      "Epoch 83/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1561 - accuracy: 0.9965 - val_loss: 0.1804 - val_accuracy: 0.9896\n",
      "Epoch 84/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1477 - accuracy: 0.9970 - val_loss: 0.1792 - val_accuracy: 0.9878\n",
      "Epoch 85/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1507 - accuracy: 0.9948 - val_loss: 0.1741 - val_accuracy: 0.9843\n",
      "Epoch 86/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1438 - accuracy: 0.9943 - val_loss: 0.2278 - val_accuracy: 0.9670\n",
      "Epoch 87/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1443 - accuracy: 0.9943 - val_loss: 0.2179 - val_accuracy: 0.9652\n",
      "Epoch 88/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1393 - accuracy: 0.9957 - val_loss: 0.1920 - val_accuracy: 0.9757\n",
      "Epoch 89/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1406 - accuracy: 0.9926 - val_loss: 0.2696 - val_accuracy: 0.9670\n",
      "Epoch 90/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1352 - accuracy: 0.9965 - val_loss: 0.1521 - val_accuracy: 0.9896\n",
      "Epoch 91/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1432 - accuracy: 0.9904 - val_loss: 0.1947 - val_accuracy: 0.9722\n",
      "Epoch 92/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1287 - accuracy: 0.9957 - val_loss: 0.1845 - val_accuracy: 0.9861\n",
      "Epoch 93/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1284 - accuracy: 0.9943 - val_loss: 0.1825 - val_accuracy: 0.9791\n",
      "Epoch 94/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1332 - accuracy: 0.9926 - val_loss: 0.1840 - val_accuracy: 0.9739\n",
      "Epoch 95/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1336 - accuracy: 0.9909 - val_loss: 0.1602 - val_accuracy: 0.9861\n",
      "Epoch 96/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1107 - accuracy: 0.9987 - val_loss: 0.1303 - val_accuracy: 0.9913\n",
      "Epoch 97/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1038 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9896\n",
      "Epoch 98/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.1025 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9913\n",
      "Epoch 99/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.1016 - accuracy: 0.9996 - val_loss: 0.1198 - val_accuracy: 0.9930\n",
      "Epoch 100/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0995 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9913\n",
      "Epoch 101/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0988 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9913\n",
      "Epoch 102/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0972 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9930\n",
      "Epoch 103/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0955 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9930\n",
      "Epoch 104/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9913\n",
      "Epoch 105/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9913\n",
      "Epoch 106/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0924 - accuracy: 0.9996 - val_loss: 0.1131 - val_accuracy: 0.9930\n",
      "Epoch 107/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0908 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9930\n",
      "Epoch 108/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0896 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9913\n",
      "Epoch 109/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0883 - accuracy: 1.0000 - val_loss: 0.1111 - val_accuracy: 0.9930\n",
      "Epoch 110/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0874 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9930\n",
      "Epoch 111/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0858 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9930\n",
      "Epoch 112/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0850 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9930\n",
      "Epoch 113/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0847 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9948\n",
      "Epoch 114/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9930\n",
      "Epoch 115/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0813 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9913\n",
      "Epoch 116/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0818 - accuracy: 0.9996 - val_loss: 0.1059 - val_accuracy: 0.9913\n",
      "Epoch 117/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0795 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9965\n",
      "Epoch 118/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0783 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9930\n",
      "Epoch 119/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0775 - accuracy: 1.0000 - val_loss: 0.0999 - val_accuracy: 0.9965\n",
      "Epoch 120/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0764 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9930\n",
      "Epoch 121/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.0990 - val_accuracy: 0.9896\n",
      "Epoch 122/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0748 - accuracy: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9930\n",
      "Epoch 123/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0733 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9930\n",
      "Epoch 124/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0723 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9913\n",
      "Epoch 125/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0717 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9930\n",
      "Epoch 126/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0702 - accuracy: 1.0000 - val_loss: 0.0949 - val_accuracy: 0.9913\n",
      "Epoch 127/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9913\n",
      "Epoch 128/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0683 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9896\n",
      "Epoch 129/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0676 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9930\n",
      "Epoch 130/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0680 - accuracy: 0.9996 - val_loss: 0.0940 - val_accuracy: 0.9913\n",
      "Epoch 131/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0659 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9965\n",
      "Epoch 132/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0662 - accuracy: 0.9996 - val_loss: 0.0967 - val_accuracy: 0.9896\n",
      "Epoch 133/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9896\n",
      "Epoch 134/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0640 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9913\n",
      "Epoch 135/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0628 - accuracy: 1.0000 - val_loss: 0.0897 - val_accuracy: 0.9930\n",
      "Epoch 136/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 0.9930\n",
      "Epoch 137/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0610 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9930\n",
      "Epoch 138/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0609 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9930\n",
      "Epoch 139/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0607 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9930\n",
      "Epoch 140/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0603 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9930\n",
      "Epoch 141/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0602 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9930\n",
      "Epoch 142/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0599 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9913\n",
      "Epoch 143/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0600 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9948\n",
      "Epoch 144/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9930\n",
      "Epoch 145/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9930\n",
      "Epoch 146/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0595 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9930\n",
      "Epoch 147/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9930\n",
      "Epoch 148/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9930\n",
      "Epoch 149/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9930\n",
      "Epoch 150/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9930\n",
      "Epoch 151/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0586 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9930\n",
      "Epoch 152/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9930\n",
      "Epoch 153/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9930\n",
      "Epoch 154/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9930\n",
      "Epoch 155/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9930\n",
      "Epoch 156/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9930\n",
      "Epoch 157/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9930\n",
      "Epoch 158/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0581 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9930\n",
      "Epoch 159/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9948\n",
      "Epoch 160/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 0.0807 - val_accuracy: 0.9930\n",
      "Epoch 161/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9930\n",
      "Epoch 162/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0579 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9930\n",
      "Epoch 163/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0584 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9930\n",
      "Epoch 164/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0580 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9913\n",
      "Epoch 165/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9913\n",
      "Epoch 166/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9930\n",
      "Epoch 167/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9930\n",
      "Epoch 168/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9930\n",
      "Epoch 169/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9930\n",
      "Epoch 170/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9930\n",
      "Epoch 171/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9930\n",
      "Epoch 172/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0576 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9930\n",
      "Epoch 173/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9930\n",
      "Epoch 174/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9930\n",
      "Epoch 175/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0574 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9930\n",
      "Epoch 176/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0571 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9948\n",
      "Epoch 177/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0570 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9948\n",
      "Epoch 178/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9948\n",
      "Epoch 179/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9948\n",
      "Epoch 180/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9948\n",
      "Epoch 181/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9948\n",
      "Epoch 182/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0568 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9948\n",
      "Epoch 183/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9930\n",
      "Epoch 184/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9930\n",
      "Epoch 185/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0566 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9948\n",
      "Epoch 186/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9948\n",
      "Epoch 187/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0564 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9930\n",
      "Epoch 188/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0562 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9913\n",
      "Epoch 189/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9913\n",
      "Epoch 190/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0563 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9913\n",
      "Epoch 191/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9913\n",
      "Epoch 192/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9913\n",
      "Epoch 193/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9913\n",
      "Epoch 194/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9913\n",
      "Epoch 195/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0560 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9930\n",
      "Epoch 196/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9930\n",
      "Epoch 197/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0555 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9913\n",
      "Epoch 198/200\n",
      "72/72 [==============================] - 1s 17ms/step - loss: 0.0558 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9913\n",
      "Epoch 199/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.0780 - val_accuracy: 0.9930\n",
      "Epoch 200/200\n",
      "72/72 [==============================] - 1s 16ms/step - loss: 0.0556 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9930\n"
     ]
    }
   ],
   "source": [
    "counter_2 +=200\n",
    "print('current_epochs',counter_2)\n",
    "contextmenu_model = fit_model(contextmenu_model,contextmenu_X_train,contextmenu_y_train,contextmenu_X_val,contextmenu_y_val,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2924a780-72aa-4ec8-a84d-ab15b36d7f05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epochs 100\n",
      "Epoch 1/100\n",
      "339/339 [==============================] - 9s 18ms/step - loss: 11.5680 - accuracy: 0.7037 - val_loss: 11.1736 - val_accuracy: 0.7190\n",
      "Epoch 2/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 8.8325 - accuracy: 0.9151 - val_loss: 7.8780 - val_accuracy: 0.9523\n",
      "Epoch 3/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 7.0647 - accuracy: 0.9514 - val_loss: 6.3402 - val_accuracy: 0.9682\n",
      "Epoch 4/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 5.7577 - accuracy: 0.9636 - val_loss: 5.1776 - val_accuracy: 0.9786\n",
      "Epoch 5/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 4.7159 - accuracy: 0.9698 - val_loss: 4.2706 - val_accuracy: 0.9771\n",
      "Epoch 6/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 3.8661 - accuracy: 0.9779 - val_loss: 3.5000 - val_accuracy: 0.9808\n",
      "Epoch 7/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 3.1660 - accuracy: 0.9811 - val_loss: 2.8896 - val_accuracy: 0.9774\n",
      "Epoch 8/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 2.6015 - accuracy: 0.9818 - val_loss: 2.3683 - val_accuracy: 0.9837\n",
      "Epoch 9/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 2.1269 - accuracy: 0.9847 - val_loss: 1.9540 - val_accuracy: 0.9804\n",
      "Epoch 10/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 1.7536 - accuracy: 0.9862 - val_loss: 1.5934 - val_accuracy: 0.9856\n",
      "Epoch 11/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 1.4478 - accuracy: 0.9853 - val_loss: 1.3336 - val_accuracy: 0.9830\n",
      "Epoch 12/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 1.2102 - accuracy: 0.9835 - val_loss: 1.1175 - val_accuracy: 0.9856\n",
      "Epoch 13/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 1.0134 - accuracy: 0.9845 - val_loss: 0.9415 - val_accuracy: 0.9804\n",
      "Epoch 14/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.8548 - accuracy: 0.9866 - val_loss: 0.7987 - val_accuracy: 0.9860\n",
      "Epoch 15/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.7240 - accuracy: 0.9856 - val_loss: 0.6851 - val_accuracy: 0.9815\n",
      "Epoch 16/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.6207 - accuracy: 0.9863 - val_loss: 0.5839 - val_accuracy: 0.9837\n",
      "Epoch 17/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.5313 - accuracy: 0.9878 - val_loss: 0.5079 - val_accuracy: 0.9856\n",
      "Epoch 18/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.4632 - accuracy: 0.9861 - val_loss: 0.4494 - val_accuracy: 0.9800\n",
      "Epoch 19/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.4006 - accuracy: 0.9876 - val_loss: 0.3793 - val_accuracy: 0.9860\n",
      "Epoch 20/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.3574 - accuracy: 0.9868 - val_loss: 0.3477 - val_accuracy: 0.9837\n",
      "Epoch 21/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.3164 - accuracy: 0.9879 - val_loss: 0.3063 - val_accuracy: 0.9852\n",
      "Epoch 22/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.2804 - accuracy: 0.9888 - val_loss: 0.2660 - val_accuracy: 0.9889\n",
      "Epoch 23/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.2601 - accuracy: 0.9869 - val_loss: 0.2422 - val_accuracy: 0.9893\n",
      "Epoch 24/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.2356 - accuracy: 0.9875 - val_loss: 0.2421 - val_accuracy: 0.9856\n",
      "Epoch 25/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.2163 - accuracy: 0.9878 - val_loss: 0.2373 - val_accuracy: 0.9797\n",
      "Epoch 26/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1961 - accuracy: 0.9900 - val_loss: 0.2068 - val_accuracy: 0.9867\n",
      "Epoch 27/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1881 - accuracy: 0.9880 - val_loss: 0.1953 - val_accuracy: 0.9856\n",
      "Epoch 28/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1774 - accuracy: 0.9864 - val_loss: 0.1733 - val_accuracy: 0.9878\n",
      "Epoch 29/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1658 - accuracy: 0.9889 - val_loss: 0.1918 - val_accuracy: 0.9797\n",
      "Epoch 30/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1604 - accuracy: 0.9882 - val_loss: 0.1579 - val_accuracy: 0.9871\n",
      "Epoch 31/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1519 - accuracy: 0.9896 - val_loss: 0.1463 - val_accuracy: 0.9867\n",
      "Epoch 32/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1432 - accuracy: 0.9876 - val_loss: 0.1682 - val_accuracy: 0.9830\n",
      "Epoch 33/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1432 - accuracy: 0.9870 - val_loss: 0.1416 - val_accuracy: 0.9900\n",
      "Epoch 34/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1377 - accuracy: 0.9877 - val_loss: 0.1343 - val_accuracy: 0.9871\n",
      "Epoch 35/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1280 - accuracy: 0.9903 - val_loss: 0.1345 - val_accuracy: 0.9893\n",
      "Epoch 36/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1318 - accuracy: 0.9864 - val_loss: 0.1395 - val_accuracy: 0.9837\n",
      "Epoch 37/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1287 - accuracy: 0.9870 - val_loss: 0.1595 - val_accuracy: 0.9819\n",
      "Epoch 38/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1257 - accuracy: 0.9869 - val_loss: 0.1198 - val_accuracy: 0.9867\n",
      "Epoch 39/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1221 - accuracy: 0.9870 - val_loss: 0.1218 - val_accuracy: 0.9863\n",
      "Epoch 40/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1164 - accuracy: 0.9884 - val_loss: 0.1377 - val_accuracy: 0.9834\n",
      "Epoch 41/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1144 - accuracy: 0.9882 - val_loss: 0.1160 - val_accuracy: 0.9874\n",
      "Epoch 42/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1135 - accuracy: 0.9884 - val_loss: 0.1097 - val_accuracy: 0.9893\n",
      "Epoch 43/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1073 - accuracy: 0.9897 - val_loss: 0.1371 - val_accuracy: 0.9841\n",
      "Epoch 44/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1095 - accuracy: 0.9879 - val_loss: 0.1095 - val_accuracy: 0.9885\n",
      "Epoch 45/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1104 - accuracy: 0.9875 - val_loss: 0.1199 - val_accuracy: 0.9867\n",
      "Epoch 46/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1140 - accuracy: 0.9872 - val_loss: 0.1322 - val_accuracy: 0.9841\n",
      "Epoch 47/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1071 - accuracy: 0.9897 - val_loss: 0.0966 - val_accuracy: 0.9893\n",
      "Epoch 48/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0998 - accuracy: 0.9903 - val_loss: 0.1286 - val_accuracy: 0.9841\n",
      "Epoch 49/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.1049 - accuracy: 0.9882 - val_loss: 0.1181 - val_accuracy: 0.9852\n",
      "Epoch 50/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0999 - accuracy: 0.9891 - val_loss: 0.1210 - val_accuracy: 0.9837\n",
      "Epoch 51/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1017 - accuracy: 0.9887 - val_loss: 0.1023 - val_accuracy: 0.9871\n",
      "Epoch 52/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.1061 - accuracy: 0.9869 - val_loss: 0.0975 - val_accuracy: 0.9885\n",
      "Epoch 53/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0709 - accuracy: 0.9974 - val_loss: 0.0737 - val_accuracy: 0.9952\n",
      "Epoch 54/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0638 - accuracy: 0.9986 - val_loss: 0.0701 - val_accuracy: 0.9963\n",
      "Epoch 55/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0610 - accuracy: 0.9986 - val_loss: 0.0695 - val_accuracy: 0.9967\n",
      "Epoch 56/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0578 - accuracy: 0.9987 - val_loss: 0.0652 - val_accuracy: 0.9956\n",
      "Epoch 57/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0539 - accuracy: 0.9997 - val_loss: 0.0655 - val_accuracy: 0.9956\n",
      "Epoch 58/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0531 - accuracy: 0.9991 - val_loss: 0.0674 - val_accuracy: 0.9948\n",
      "Epoch 59/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0520 - accuracy: 0.9993 - val_loss: 0.0619 - val_accuracy: 0.9967\n",
      "Epoch 60/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0489 - accuracy: 0.9994 - val_loss: 0.0607 - val_accuracy: 0.9956\n",
      "Epoch 61/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0486 - accuracy: 0.9991 - val_loss: 0.0577 - val_accuracy: 0.9967\n",
      "Epoch 62/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0464 - accuracy: 0.9994 - val_loss: 0.0643 - val_accuracy: 0.9945\n",
      "Epoch 63/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0477 - accuracy: 0.9986 - val_loss: 0.0553 - val_accuracy: 0.9959\n",
      "Epoch 64/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0455 - accuracy: 0.9994 - val_loss: 0.0571 - val_accuracy: 0.9945\n",
      "Epoch 65/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0440 - accuracy: 0.9993 - val_loss: 0.0576 - val_accuracy: 0.9956\n",
      "Epoch 66/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0461 - accuracy: 0.9984 - val_loss: 0.0537 - val_accuracy: 0.9963\n",
      "Epoch 67/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0439 - accuracy: 0.9993 - val_loss: 0.0534 - val_accuracy: 0.9948\n",
      "Epoch 68/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0429 - accuracy: 0.9992 - val_loss: 0.0557 - val_accuracy: 0.9956\n",
      "Epoch 69/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0419 - accuracy: 0.9990 - val_loss: 0.0561 - val_accuracy: 0.9963\n",
      "Epoch 70/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0424 - accuracy: 0.9989 - val_loss: 0.0549 - val_accuracy: 0.9941\n",
      "Epoch 71/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0414 - accuracy: 0.9993 - val_loss: 0.0561 - val_accuracy: 0.9956\n",
      "Epoch 72/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0414 - accuracy: 0.9989 - val_loss: 0.0509 - val_accuracy: 0.9963\n",
      "Epoch 73/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0410 - accuracy: 0.9986 - val_loss: 0.0525 - val_accuracy: 0.9959\n",
      "Epoch 74/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0391 - accuracy: 0.9992 - val_loss: 0.0482 - val_accuracy: 0.9956\n",
      "Epoch 75/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0415 - accuracy: 0.9983 - val_loss: 0.0538 - val_accuracy: 0.9948\n",
      "Epoch 76/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0402 - accuracy: 0.9986 - val_loss: 0.0529 - val_accuracy: 0.9945\n",
      "Epoch 77/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0392 - accuracy: 0.9990 - val_loss: 0.0481 - val_accuracy: 0.9963\n",
      "Epoch 78/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0396 - accuracy: 0.9988 - val_loss: 0.0574 - val_accuracy: 0.9941\n",
      "Epoch 79/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0401 - accuracy: 0.9982 - val_loss: 0.0590 - val_accuracy: 0.9933\n",
      "Epoch 80/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0358 - accuracy: 0.9997 - val_loss: 0.0465 - val_accuracy: 0.9970\n",
      "Epoch 81/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0342 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 0.9970\n",
      "Epoch 82/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0341 - accuracy: 0.9999 - val_loss: 0.0445 - val_accuracy: 0.9967\n",
      "Epoch 83/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0349 - accuracy: 0.9997 - val_loss: 0.0442 - val_accuracy: 0.9967\n",
      "Epoch 84/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0341 - accuracy: 0.9999 - val_loss: 0.0439 - val_accuracy: 0.9970\n",
      "Epoch 85/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0339 - accuracy: 0.9998 - val_loss: 0.0455 - val_accuracy: 0.9967\n",
      "Epoch 86/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 0.9963\n",
      "Epoch 87/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0333 - accuracy: 0.9999 - val_loss: 0.0435 - val_accuracy: 0.9963\n",
      "Epoch 88/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9963\n",
      "Epoch 89/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0332 - accuracy: 0.9998 - val_loss: 0.0427 - val_accuracy: 0.9959\n",
      "Epoch 90/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0331 - accuracy: 0.9997 - val_loss: 0.0421 - val_accuracy: 0.9974\n",
      "Epoch 91/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0332 - accuracy: 0.9999 - val_loss: 0.0419 - val_accuracy: 0.9963\n",
      "Epoch 92/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0325 - accuracy: 0.9999 - val_loss: 0.0430 - val_accuracy: 0.9974\n",
      "Epoch 93/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0325 - accuracy: 0.9999 - val_loss: 0.0421 - val_accuracy: 0.9967\n",
      "Epoch 94/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 0.0432 - val_accuracy: 0.9963\n",
      "Epoch 95/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0328 - accuracy: 0.9997 - val_loss: 0.0400 - val_accuracy: 0.9974\n",
      "Epoch 96/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0327 - accuracy: 0.9997 - val_loss: 0.0438 - val_accuracy: 0.9967\n",
      "Epoch 97/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0322 - accuracy: 0.9999 - val_loss: 0.0400 - val_accuracy: 0.9974\n",
      "Epoch 98/100\n",
      "339/339 [==============================] - 6s 16ms/step - loss: 0.0317 - accuracy: 0.9999 - val_loss: 0.0401 - val_accuracy: 0.9970\n",
      "Epoch 99/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0317 - accuracy: 0.9999 - val_loss: 0.0413 - val_accuracy: 0.9970\n",
      "Epoch 100/100\n",
      "339/339 [==============================] - 5s 16ms/step - loss: 0.0321 - accuracy: 0.9997 - val_loss: 0.0412 - val_accuracy: 0.9970\n"
     ]
    }
   ],
   "source": [
    "counter_3 +=100\n",
    "print('current_epochs',counter_3)\n",
    "bikeyboard_model = fit_model(bikeyboard_model,bikeyboard_X_train,bikeyboard_y_train,bikeyboard_X_val,bikeyboard_y_val,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de15ae03-0918-4a2d-9a5d-9dc6385f245c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_epochs 200\n",
      "Epoch 1/200\n",
      "101/101 [==============================] - 5s 22ms/step - loss: 13.1694 - accuracy: 0.4337 - val_loss: 13.7414 - val_accuracy: 0.1176\n",
      "Epoch 2/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 11.5060 - accuracy: 0.7706 - val_loss: 12.9605 - val_accuracy: 0.2005\n",
      "Epoch 3/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 10.5391 - accuracy: 0.8721 - val_loss: 11.8537 - val_accuracy: 0.4344\n",
      "Epoch 4/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 9.7569 - accuracy: 0.9152 - val_loss: 10.5703 - val_accuracy: 0.7649\n",
      "Epoch 5/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 9.0238 - accuracy: 0.9489 - val_loss: 9.2222 - val_accuracy: 0.9245\n",
      "Epoch 6/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 8.3064 - accuracy: 0.9709 - val_loss: 8.1873 - val_accuracy: 0.9468\n",
      "Epoch 7/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 7.6496 - accuracy: 0.9789 - val_loss: 7.4532 - val_accuracy: 0.9616\n",
      "Epoch 8/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 7.0438 - accuracy: 0.9833 - val_loss: 6.8272 - val_accuracy: 0.9653\n",
      "Epoch 9/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 6.4876 - accuracy: 0.9848 - val_loss: 6.3050 - val_accuracy: 0.9653\n",
      "Epoch 10/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 6.0055 - accuracy: 0.9867 - val_loss: 5.8484 - val_accuracy: 0.9653\n",
      "Epoch 11/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 5.5429 - accuracy: 0.9910 - val_loss: 5.3641 - val_accuracy: 0.9790\n",
      "Epoch 12/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 5.0805 - accuracy: 0.9926 - val_loss: 4.9583 - val_accuracy: 0.9666\n",
      "Epoch 13/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 4.6832 - accuracy: 0.9926 - val_loss: 4.5695 - val_accuracy: 0.9728\n",
      "Epoch 14/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 4.3308 - accuracy: 0.9907 - val_loss: 4.2083 - val_accuracy: 0.9740\n",
      "Epoch 15/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 3.9904 - accuracy: 0.9938 - val_loss: 3.8811 - val_accuracy: 0.9827\n",
      "Epoch 16/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 3.6845 - accuracy: 0.9910 - val_loss: 3.5992 - val_accuracy: 0.9703\n",
      "Epoch 17/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 3.3971 - accuracy: 0.9935 - val_loss: 3.3244 - val_accuracy: 0.9703\n",
      "Epoch 18/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 3.1258 - accuracy: 0.9929 - val_loss: 3.0661 - val_accuracy: 0.9765\n",
      "Epoch 19/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 2.8892 - accuracy: 0.9913 - val_loss: 2.8330 - val_accuracy: 0.9802\n",
      "Epoch 20/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 2.6615 - accuracy: 0.9947 - val_loss: 2.5987 - val_accuracy: 0.9827\n",
      "Epoch 21/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 2.4595 - accuracy: 0.9944 - val_loss: 2.4159 - val_accuracy: 0.9802\n",
      "Epoch 22/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 2.2741 - accuracy: 0.9929 - val_loss: 2.2428 - val_accuracy: 0.9802\n",
      "Epoch 23/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 2.0951 - accuracy: 0.9929 - val_loss: 2.0608 - val_accuracy: 0.9765\n",
      "Epoch 24/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.9283 - accuracy: 0.9944 - val_loss: 1.9331 - val_accuracy: 0.9666\n",
      "Epoch 25/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.7907 - accuracy: 0.9916 - val_loss: 1.8136 - val_accuracy: 0.9740\n",
      "Epoch 26/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.6652 - accuracy: 0.9913 - val_loss: 1.6613 - val_accuracy: 0.9752\n",
      "Epoch 27/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.5370 - accuracy: 0.9941 - val_loss: 1.5623 - val_accuracy: 0.9678\n",
      "Epoch 28/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.4278 - accuracy: 0.9913 - val_loss: 1.4370 - val_accuracy: 0.9777\n",
      "Epoch 29/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.3248 - accuracy: 0.9935 - val_loss: 1.3185 - val_accuracy: 0.9790\n",
      "Epoch 30/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.2234 - accuracy: 0.9950 - val_loss: 1.2311 - val_accuracy: 0.9802\n",
      "Epoch 31/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.1374 - accuracy: 0.9938 - val_loss: 1.1532 - val_accuracy: 0.9740\n",
      "Epoch 32/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 1.0641 - accuracy: 0.9932 - val_loss: 1.0573 - val_accuracy: 0.9839\n",
      "Epoch 33/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.9959 - accuracy: 0.9916 - val_loss: 1.0057 - val_accuracy: 0.9765\n",
      "Epoch 34/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.9228 - accuracy: 0.9944 - val_loss: 0.9345 - val_accuracy: 0.9827\n",
      "Epoch 35/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.8549 - accuracy: 0.9950 - val_loss: 0.8820 - val_accuracy: 0.9790\n",
      "Epoch 36/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.7905 - accuracy: 0.9969 - val_loss: 0.8288 - val_accuracy: 0.9814\n",
      "Epoch 37/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.7366 - accuracy: 0.9950 - val_loss: 0.7440 - val_accuracy: 0.9851\n",
      "Epoch 38/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.6775 - accuracy: 0.9966 - val_loss: 0.7328 - val_accuracy: 0.9752\n",
      "Epoch 39/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.6427 - accuracy: 0.9926 - val_loss: 0.7032 - val_accuracy: 0.9728\n",
      "Epoch 40/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.6157 - accuracy: 0.9885 - val_loss: 0.6250 - val_accuracy: 0.9740\n",
      "Epoch 41/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.5851 - accuracy: 0.9898 - val_loss: 0.6534 - val_accuracy: 0.9616\n",
      "Epoch 42/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.5487 - accuracy: 0.9916 - val_loss: 0.5809 - val_accuracy: 0.9839\n",
      "Epoch 43/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.5145 - accuracy: 0.9926 - val_loss: 0.5488 - val_accuracy: 0.9752\n",
      "Epoch 44/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.4862 - accuracy: 0.9913 - val_loss: 0.5056 - val_accuracy: 0.9851\n",
      "Epoch 45/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.4452 - accuracy: 0.9963 - val_loss: 0.4663 - val_accuracy: 0.9839\n",
      "Epoch 46/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.4157 - accuracy: 0.9957 - val_loss: 0.4682 - val_accuracy: 0.9728\n",
      "Epoch 47/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.4014 - accuracy: 0.9944 - val_loss: 0.4201 - val_accuracy: 0.9864\n",
      "Epoch 48/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.3646 - accuracy: 0.9975 - val_loss: 0.4035 - val_accuracy: 0.9790\n",
      "Epoch 49/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.3616 - accuracy: 0.9898 - val_loss: 0.3707 - val_accuracy: 0.9827\n",
      "Epoch 50/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.3301 - accuracy: 0.9947 - val_loss: 0.3588 - val_accuracy: 0.9814\n",
      "Epoch 51/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.3168 - accuracy: 0.9929 - val_loss: 0.3606 - val_accuracy: 0.9802\n",
      "Epoch 52/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.3046 - accuracy: 0.9910 - val_loss: 0.3204 - val_accuracy: 0.9839\n",
      "Epoch 53/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2828 - accuracy: 0.9944 - val_loss: 0.3183 - val_accuracy: 0.9839\n",
      "Epoch 54/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2730 - accuracy: 0.9938 - val_loss: 0.3182 - val_accuracy: 0.9765\n",
      "Epoch 55/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2683 - accuracy: 0.9907 - val_loss: 0.3393 - val_accuracy: 0.9728\n",
      "Epoch 56/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.2494 - accuracy: 0.9935 - val_loss: 0.2876 - val_accuracy: 0.9814\n",
      "Epoch 57/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2440 - accuracy: 0.9913 - val_loss: 0.2740 - val_accuracy: 0.9876\n",
      "Epoch 58/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2247 - accuracy: 0.9966 - val_loss: 0.2767 - val_accuracy: 0.9752\n",
      "Epoch 59/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.2227 - accuracy: 0.9944 - val_loss: 0.2671 - val_accuracy: 0.9740\n",
      "Epoch 60/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2108 - accuracy: 0.9944 - val_loss: 0.2246 - val_accuracy: 0.9851\n",
      "Epoch 61/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2020 - accuracy: 0.9944 - val_loss: 0.2670 - val_accuracy: 0.9728\n",
      "Epoch 62/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.2026 - accuracy: 0.9916 - val_loss: 0.2283 - val_accuracy: 0.9790\n",
      "Epoch 63/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1948 - accuracy: 0.9916 - val_loss: 0.2260 - val_accuracy: 0.9777\n",
      "Epoch 64/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1919 - accuracy: 0.9932 - val_loss: 0.2627 - val_accuracy: 0.9740\n",
      "Epoch 65/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1684 - accuracy: 0.9969 - val_loss: 0.1885 - val_accuracy: 0.9889\n",
      "Epoch 66/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1658 - accuracy: 0.9941 - val_loss: 0.2005 - val_accuracy: 0.9790\n",
      "Epoch 67/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1620 - accuracy: 0.9954 - val_loss: 0.1909 - val_accuracy: 0.9827\n",
      "Epoch 68/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1546 - accuracy: 0.9963 - val_loss: 0.1899 - val_accuracy: 0.9827\n",
      "Epoch 69/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1660 - accuracy: 0.9920 - val_loss: 0.2097 - val_accuracy: 0.9752\n",
      "Epoch 70/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1534 - accuracy: 0.9907 - val_loss: 0.1702 - val_accuracy: 0.9864\n",
      "Epoch 71/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1451 - accuracy: 0.9935 - val_loss: 0.2279 - val_accuracy: 0.9715\n",
      "Epoch 72/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1378 - accuracy: 0.9957 - val_loss: 0.1828 - val_accuracy: 0.9802\n",
      "Epoch 73/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1392 - accuracy: 0.9932 - val_loss: 0.2120 - val_accuracy: 0.9790\n",
      "Epoch 74/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1675 - accuracy: 0.9864 - val_loss: 0.1600 - val_accuracy: 0.9839\n",
      "Epoch 75/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1333 - accuracy: 0.9950 - val_loss: 0.1741 - val_accuracy: 0.9802\n",
      "Epoch 76/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1253 - accuracy: 0.9957 - val_loss: 0.1631 - val_accuracy: 0.9802\n",
      "Epoch 77/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1262 - accuracy: 0.9954 - val_loss: 0.1683 - val_accuracy: 0.9777\n",
      "Epoch 78/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1231 - accuracy: 0.9944 - val_loss: 0.1672 - val_accuracy: 0.9765\n",
      "Epoch 79/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1277 - accuracy: 0.9923 - val_loss: 0.1670 - val_accuracy: 0.9827\n",
      "Epoch 80/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.1069 - accuracy: 0.9972 - val_loss: 0.1227 - val_accuracy: 0.9913\n",
      "Epoch 81/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0994 - accuracy: 0.9997 - val_loss: 0.1152 - val_accuracy: 0.9950\n",
      "Epoch 82/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0974 - accuracy: 0.9997 - val_loss: 0.1137 - val_accuracy: 0.9926\n",
      "Epoch 83/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0959 - accuracy: 0.9994 - val_loss: 0.1134 - val_accuracy: 0.9938\n",
      "Epoch 84/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0937 - accuracy: 0.9997 - val_loss: 0.1104 - val_accuracy: 0.9938\n",
      "Epoch 85/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0919 - accuracy: 0.9997 - val_loss: 0.1093 - val_accuracy: 0.9913\n",
      "Epoch 86/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0906 - accuracy: 0.9997 - val_loss: 0.1062 - val_accuracy: 0.9975\n",
      "Epoch 87/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0890 - accuracy: 0.9994 - val_loss: 0.1033 - val_accuracy: 0.9975\n",
      "Epoch 88/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0897 - accuracy: 0.9994 - val_loss: 0.1133 - val_accuracy: 0.9913\n",
      "Epoch 89/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0862 - accuracy: 0.9997 - val_loss: 0.1028 - val_accuracy: 0.9975\n",
      "Epoch 90/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0847 - accuracy: 0.9997 - val_loss: 0.0988 - val_accuracy: 0.9975\n",
      "Epoch 91/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0841 - accuracy: 0.9997 - val_loss: 0.1015 - val_accuracy: 0.9950\n",
      "Epoch 92/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0827 - accuracy: 0.9994 - val_loss: 0.0991 - val_accuracy: 0.9938\n",
      "Epoch 93/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0813 - accuracy: 0.9994 - val_loss: 0.0991 - val_accuracy: 0.9938\n",
      "Epoch 94/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0794 - accuracy: 0.9997 - val_loss: 0.0973 - val_accuracy: 0.9938\n",
      "Epoch 95/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0779 - accuracy: 0.9997 - val_loss: 0.0950 - val_accuracy: 0.9963\n",
      "Epoch 96/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0772 - accuracy: 0.9997 - val_loss: 0.1014 - val_accuracy: 0.9901\n",
      "Epoch 97/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0752 - accuracy: 0.9997 - val_loss: 0.0913 - val_accuracy: 0.9975\n",
      "Epoch 98/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0738 - accuracy: 0.9997 - val_loss: 0.0953 - val_accuracy: 0.9926\n",
      "Epoch 99/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0731 - accuracy: 0.9994 - val_loss: 0.0896 - val_accuracy: 0.9975\n",
      "Epoch 100/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0713 - accuracy: 0.9997 - val_loss: 0.0895 - val_accuracy: 0.9938\n",
      "Epoch 101/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0708 - accuracy: 0.9997 - val_loss: 0.0885 - val_accuracy: 0.9950\n",
      "Epoch 102/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0698 - accuracy: 0.9997 - val_loss: 0.0995 - val_accuracy: 0.9889\n",
      "Epoch 103/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0684 - accuracy: 0.9997 - val_loss: 0.0873 - val_accuracy: 0.9938\n",
      "Epoch 104/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0677 - accuracy: 0.9994 - val_loss: 0.0851 - val_accuracy: 0.9950\n",
      "Epoch 105/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0665 - accuracy: 0.9994 - val_loss: 0.0874 - val_accuracy: 0.9938\n",
      "Epoch 106/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0657 - accuracy: 0.9997 - val_loss: 0.0796 - val_accuracy: 0.9950\n",
      "Epoch 107/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0654 - accuracy: 0.9994 - val_loss: 0.0844 - val_accuracy: 0.9938\n",
      "Epoch 108/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0643 - accuracy: 0.9997 - val_loss: 0.0805 - val_accuracy: 0.9938\n",
      "Epoch 109/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0632 - accuracy: 0.9997 - val_loss: 0.0881 - val_accuracy: 0.9913\n",
      "Epoch 110/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0617 - accuracy: 0.9997 - val_loss: 0.0798 - val_accuracy: 0.9938\n",
      "Epoch 111/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0610 - accuracy: 0.9994 - val_loss: 0.0750 - val_accuracy: 0.9938\n",
      "Epoch 112/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0609 - accuracy: 0.9994 - val_loss: 0.0886 - val_accuracy: 0.9876\n",
      "Epoch 113/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0602 - accuracy: 0.9994 - val_loss: 0.0821 - val_accuracy: 0.9901\n",
      "Epoch 114/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0585 - accuracy: 0.9997 - val_loss: 0.0744 - val_accuracy: 0.9950\n",
      "Epoch 115/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0578 - accuracy: 0.9997 - val_loss: 0.0871 - val_accuracy: 0.9913\n",
      "Epoch 116/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0579 - accuracy: 0.9994 - val_loss: 0.0756 - val_accuracy: 0.9913\n",
      "Epoch 117/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0583 - accuracy: 0.9991 - val_loss: 0.0746 - val_accuracy: 0.9901\n",
      "Epoch 118/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0560 - accuracy: 0.9997 - val_loss: 0.0737 - val_accuracy: 0.9938\n",
      "Epoch 119/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0549 - accuracy: 0.9997 - val_loss: 0.0833 - val_accuracy: 0.9926\n",
      "Epoch 120/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0558 - accuracy: 0.9997 - val_loss: 0.0774 - val_accuracy: 0.9913\n",
      "Epoch 121/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0539 - accuracy: 0.9997 - val_loss: 0.0766 - val_accuracy: 0.9901\n",
      "Epoch 122/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0551 - accuracy: 0.9994 - val_loss: 0.0738 - val_accuracy: 0.9913\n",
      "Epoch 123/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0526 - accuracy: 0.9997 - val_loss: 0.0700 - val_accuracy: 0.9950\n",
      "Epoch 124/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0523 - accuracy: 0.9997 - val_loss: 0.0710 - val_accuracy: 0.9938\n",
      "Epoch 125/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0512 - accuracy: 0.9997 - val_loss: 0.0702 - val_accuracy: 0.9913\n",
      "Epoch 126/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0511 - accuracy: 0.9997 - val_loss: 0.0796 - val_accuracy: 0.9901\n",
      "Epoch 127/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0504 - accuracy: 0.9997 - val_loss: 0.0698 - val_accuracy: 0.9950\n",
      "Epoch 128/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0511 - accuracy: 0.9991 - val_loss: 0.0614 - val_accuracy: 0.9988\n",
      "Epoch 129/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0499 - accuracy: 0.9994 - val_loss: 0.0626 - val_accuracy: 0.9975\n",
      "Epoch 130/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0498 - accuracy: 0.9994 - val_loss: 0.0643 - val_accuracy: 0.9913\n",
      "Epoch 131/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0494 - accuracy: 0.9991 - val_loss: 0.0660 - val_accuracy: 0.9926\n",
      "Epoch 132/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0494 - accuracy: 0.9991 - val_loss: 0.0719 - val_accuracy: 0.9901\n",
      "Epoch 133/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0473 - accuracy: 0.9997 - val_loss: 0.0654 - val_accuracy: 0.9938\n",
      "Epoch 134/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0464 - accuracy: 0.9997 - val_loss: 0.0636 - val_accuracy: 0.9926\n",
      "Epoch 135/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0459 - accuracy: 0.9997 - val_loss: 0.0618 - val_accuracy: 0.9950\n",
      "Epoch 136/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0458 - accuracy: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9950\n",
      "Epoch 137/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0455 - accuracy: 0.9997 - val_loss: 0.0607 - val_accuracy: 0.9938\n",
      "Epoch 138/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0457 - accuracy: 0.9997 - val_loss: 0.0610 - val_accuracy: 0.9950\n",
      "Epoch 139/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0458 - accuracy: 0.9997 - val_loss: 0.0596 - val_accuracy: 0.9963\n",
      "Epoch 140/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 0.9963\n",
      "Epoch 141/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0453 - accuracy: 0.9997 - val_loss: 0.0613 - val_accuracy: 0.9938\n",
      "Epoch 142/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0450 - accuracy: 0.9997 - val_loss: 0.0602 - val_accuracy: 0.9950\n",
      "Epoch 143/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0450 - accuracy: 0.9997 - val_loss: 0.0596 - val_accuracy: 0.9963\n",
      "Epoch 144/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0445 - accuracy: 0.9997 - val_loss: 0.0592 - val_accuracy: 0.9963\n",
      "Epoch 145/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0445 - accuracy: 0.9997 - val_loss: 0.0595 - val_accuracy: 0.9950\n",
      "Epoch 146/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0440 - accuracy: 0.9997 - val_loss: 0.0599 - val_accuracy: 0.9950\n",
      "Epoch 147/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9950\n",
      "Epoch 148/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0443 - accuracy: 0.9997 - val_loss: 0.0583 - val_accuracy: 0.9950\n",
      "Epoch 149/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0437 - accuracy: 0.9997 - val_loss: 0.0573 - val_accuracy: 0.9963\n",
      "Epoch 150/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0438 - accuracy: 0.9997 - val_loss: 0.0601 - val_accuracy: 0.9938\n",
      "Epoch 151/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0438 - accuracy: 0.9997 - val_loss: 0.0580 - val_accuracy: 0.9938\n",
      "Epoch 152/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0445 - accuracy: 0.9994 - val_loss: 0.0609 - val_accuracy: 0.9950\n",
      "Epoch 153/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0436 - accuracy: 0.9997 - val_loss: 0.0553 - val_accuracy: 0.9963\n",
      "Epoch 154/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0432 - accuracy: 0.9997 - val_loss: 0.0556 - val_accuracy: 0.9963\n",
      "Epoch 155/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0433 - accuracy: 0.9997 - val_loss: 0.0565 - val_accuracy: 0.9950\n",
      "Epoch 156/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0430 - accuracy: 0.9997 - val_loss: 0.0565 - val_accuracy: 0.9975\n",
      "Epoch 157/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0430 - accuracy: 0.9997 - val_loss: 0.0556 - val_accuracy: 0.9963\n",
      "Epoch 158/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0429 - accuracy: 0.9997 - val_loss: 0.0559 - val_accuracy: 0.9963\n",
      "Epoch 159/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0425 - accuracy: 0.9997 - val_loss: 0.0554 - val_accuracy: 0.9963\n",
      "Epoch 160/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0428 - accuracy: 0.9997 - val_loss: 0.0545 - val_accuracy: 0.9975\n",
      "Epoch 161/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0426 - accuracy: 0.9997 - val_loss: 0.0554 - val_accuracy: 0.9963\n",
      "Epoch 162/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0424 - accuracy: 0.9997 - val_loss: 0.0548 - val_accuracy: 0.9975\n",
      "Epoch 163/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0423 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9963\n",
      "Epoch 164/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0423 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9963\n",
      "Epoch 165/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0423 - accuracy: 0.9997 - val_loss: 0.0554 - val_accuracy: 0.9963\n",
      "Epoch 166/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0422 - accuracy: 0.9997 - val_loss: 0.0555 - val_accuracy: 0.9975\n",
      "Epoch 167/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0423 - accuracy: 0.9997 - val_loss: 0.0549 - val_accuracy: 0.9975\n",
      "Epoch 168/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0422 - accuracy: 0.9997 - val_loss: 0.0549 - val_accuracy: 0.9975\n",
      "Epoch 169/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0424 - accuracy: 0.9997 - val_loss: 0.0554 - val_accuracy: 0.9963\n",
      "Epoch 170/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0421 - accuracy: 0.9997 - val_loss: 0.0556 - val_accuracy: 0.9963\n",
      "Epoch 171/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0419 - accuracy: 0.9997 - val_loss: 0.0559 - val_accuracy: 0.9963\n",
      "Epoch 172/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0419 - accuracy: 0.9997 - val_loss: 0.0551 - val_accuracy: 0.9963\n",
      "Epoch 173/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0419 - accuracy: 0.9997 - val_loss: 0.0551 - val_accuracy: 0.9975\n",
      "Epoch 174/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0419 - accuracy: 0.9997 - val_loss: 0.0559 - val_accuracy: 0.9963\n",
      "Epoch 175/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0418 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9963\n",
      "Epoch 176/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0420 - accuracy: 0.9997 - val_loss: 0.0565 - val_accuracy: 0.9950\n",
      "Epoch 177/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0419 - accuracy: 0.9997 - val_loss: 0.0561 - val_accuracy: 0.9950\n",
      "Epoch 178/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0418 - accuracy: 0.9997 - val_loss: 0.0567 - val_accuracy: 0.9950\n",
      "Epoch 179/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0418 - accuracy: 0.9997 - val_loss: 0.0560 - val_accuracy: 0.9963\n",
      "Epoch 180/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0419 - accuracy: 0.9997 - val_loss: 0.0563 - val_accuracy: 0.9950\n",
      "Epoch 181/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0415 - accuracy: 0.9997 - val_loss: 0.0558 - val_accuracy: 0.9950\n",
      "Epoch 182/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0418 - accuracy: 0.9997 - val_loss: 0.0555 - val_accuracy: 0.9950\n",
      "Epoch 183/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0417 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9950\n",
      "Epoch 184/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0415 - accuracy: 0.9997 - val_loss: 0.0554 - val_accuracy: 0.9963\n",
      "Epoch 185/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0414 - accuracy: 0.9997 - val_loss: 0.0553 - val_accuracy: 0.9963\n",
      "Epoch 186/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0414 - accuracy: 0.9997 - val_loss: 0.0553 - val_accuracy: 0.9950\n",
      "Epoch 187/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0414 - accuracy: 0.9997 - val_loss: 0.0549 - val_accuracy: 0.9963\n",
      "Epoch 188/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0414 - accuracy: 0.9997 - val_loss: 0.0551 - val_accuracy: 0.9950\n",
      "Epoch 189/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0414 - accuracy: 0.9997 - val_loss: 0.0550 - val_accuracy: 0.9963\n",
      "Epoch 190/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0413 - accuracy: 0.9997 - val_loss: 0.0545 - val_accuracy: 0.9975\n",
      "Epoch 191/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0413 - accuracy: 0.9997 - val_loss: 0.0548 - val_accuracy: 0.9963\n",
      "Epoch 192/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0410 - accuracy: 0.9997 - val_loss: 0.0550 - val_accuracy: 0.9963\n",
      "Epoch 193/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0413 - accuracy: 0.9997 - val_loss: 0.0545 - val_accuracy: 0.9963\n",
      "Epoch 194/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0410 - accuracy: 0.9997 - val_loss: 0.0549 - val_accuracy: 0.9963\n",
      "Epoch 195/200\n",
      "101/101 [==============================] - 2s 17ms/step - loss: 0.0411 - accuracy: 0.9997 - val_loss: 0.0560 - val_accuracy: 0.9950\n",
      "Epoch 196/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0410 - accuracy: 0.9997 - val_loss: 0.0556 - val_accuracy: 0.9963\n",
      "Epoch 197/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0412 - accuracy: 0.9997 - val_loss: 0.0554 - val_accuracy: 0.9963\n",
      "Epoch 198/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0411 - accuracy: 0.9997 - val_loss: 0.0560 - val_accuracy: 0.9963\n",
      "Epoch 199/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0409 - accuracy: 0.9997 - val_loss: 0.0563 - val_accuracy: 0.9950\n",
      "Epoch 200/200\n",
      "101/101 [==============================] - 2s 16ms/step - loss: 0.0410 - accuracy: 0.9997 - val_loss: 0.0557 - val_accuracy: 0.9950\n"
     ]
    }
   ],
   "source": [
    "counter_4 +=200\n",
    "print('current_epochs',counter_4)\n",
    "rescal_model = fit_model(rescale_model,rescale_X_train,rescale_y_train,rescale_X_val,rescale_y_val,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e791c367-88f8-44fc-ba9c-893baa02ee1f",
   "metadata": {},
   "source": [
    "<h3>Modellevaluierung</h3>\n",
    "Die Modelle werden mit den Validierungsdaten bewertet.<br>\n",
    " Folgende Metriken wurden hier erstellt:<br>\n",
    "  - Genauigkeit (accuracy)<br>\n",
    "  - Konfusionsmatrix (confusion matrix)<br>\n",
    "  - Klassifikationsberichte (classification report)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "191c352f-884d-42c7-8206-f35dd95ac019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_val(model, X_val, y_val):\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val)\n",
    "    print(f'Validation loss: {val_loss}')\n",
    "    print(f'Validation accuracy: {val_accuracy}')\n",
    "\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_val_pred, axis=1)\n",
    "    y_val_true = y_val.argmax(axis=-1)\n",
    "    \n",
    "    print(classification_report(y_val_true, y_pred_classes))\n",
    "    conf_matrix = confusion_matrix(y_val_true, y_pred_classes)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "    plt.title('Confusion Matrix - VAlidation Data')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1cfb6-ece4-49eb-8c12-4c3d9eefc62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_val(reposition_model_79,reposition_X_val, reposition_y_val)\n",
    "eval_val(contextmenu_model_85,contextmenu_X_val, contextmenu_y_val)\n",
    "eval_val(bikeyboard_model_91,bikeyboard_X_val, bikeyboard_y_val)\n",
    "eval_val(rescale_model_82,rescale_X_val, rescale_y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac193a-8cdd-4884-87fb-5cf15bd6c514",
   "metadata": {},
   "source": [
    "<h3>Eine Majority Voting wird angewendet, um die Vorhersagen zu verbessern.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e53dd05-1ae1-4909-96d3-0a5118910fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_voting(predictions, window_size, step_size):\n",
    "\n",
    "    # Anzahl der Fenster in den Vorhersagen\n",
    "    num_windows = predictions.shape[0]\n",
    "    interaction_predictions = []\n",
    "\n",
    "    # Iteriere über die Fenster mit einem bestimmten Schritt\n",
    "    for i in range(0, num_windows * step_size, step_size):\n",
    "        window_start = i // step_size\n",
    "        window_end =(i + window_size) // step_size\n",
    "        # Stelle sicher, dass das Endfenster nicht über die Anzahl der Fenster hinausgeht\n",
    "        if window_end > num_windows:\n",
    "            window_end = num_windows\n",
    "        # Sammle die Vorhersagen innerhalb des aktuellen Fensters\n",
    "        window_preds = predictions[window_start:window_end]\n",
    "\n",
    "        # Führe eine Mehrheitsabstimmung innerhalb des Fensters durch und füge das Ergebnis hinzu\n",
    "        if len(window_preds) > 0:\n",
    "            final_pred = mode(window_preds).mode[0]\n",
    "            interaction_predictions.append(final_pred)\n",
    "    return np.array(interaction_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da43bb2e-8341-4901-8793-952adcc77421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_result(model,X_test,y_test,window_size, step_size):\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f'Test loss: {test_loss}')\n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "    # Bestimmen der Vorhersagen.\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    # Bestimmen der vorhergesagten Klassen.\n",
    "    y_test_pred_classes = y_test_pred.argmax(axis=-1)\n",
    "    # Klassen extrahieren\n",
    "    y_test_true = y_test.argmax(axis=-1)\n",
    "    \n",
    "    final_test_predictions = majority_voting(y_test_pred_classes, window_size,step_size)\n",
    "    \n",
    "    print(classification_report(y_test_true, final_test_predictions, zero_division=0))\n",
    "    conf_matrix = confusion_matrix(y_test_true, final_test_predictions)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "    # Konfusionsmatrix als Heatmap anzeigen\n",
    "    plt.title('Confusion Matrix - Test Data (Majority Voting)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f352daad-8d84-465e-b726-20d1de69b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_save_path = 'reposition_uid_model.h5'\n",
    "# reposition_model.save(model_save_path)\n",
    "\n",
    "# model_save_path = 'contextmenu_uid_model.h5'\n",
    "# contextmenu_model.save(model_save_path)\n",
    "\n",
    "# model_save_path = 'bikeyboard_uid_model.h5'\n",
    "# bikeyboard_model.save(model_save_path)\n",
    "\n",
    "# model_save_path = 'rescale_uid_model.h5'\n",
    "# rescale_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21ae50-bd55-4089-8327-e344ce483fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reposition_model_79= tf.keras.models.load_model('reposition_uid_model_79_230_10.h5')\n",
    "contextmenu_model_85= tf.keras.models.load_model('contextmenu_uid_model_85_165_5.h5')\n",
    "bikeyboard_model_91= tf.keras.models.load_model('bikeyboard_uid_model_91_250_10.h5')\n",
    "rescale_model_82= tf.keras.models.load_model('rescale_uid_model_82_150_10.h5')\n",
    "show_result(reposition_model_79, reposition_X_test, reposition_y_test,230,10)\n",
    "show_result(contextmenu_model_85, contextmenu_X_test, contextmenu_y_test, 165,5)\n",
    "show_result(bikeyboard_model_91, bikeyboard_X_test, bikeyboard_y_test, 250,10)\n",
    "show_result(rescale_model_82, rescale_X_test, rescale_y_test, 150,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3b8aba7-0b90-4cf9-9975-617139bd420b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result_without_MV(model,X_test,y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_true = y_test.argmax(axis=-1)\n",
    "    \n",
    "    test_loss, test_accuracy = model.evaluate(X_test,y_test)\n",
    "    print(f'Test loss: {test_loss}')\n",
    "    print(f'Test accuracy: {test_accuracy}')\n",
    "    \n",
    "    print(classification_report(y_test_true, y_pred_classes))\n",
    "    conf_matrix = confusion_matrix(y_test_true, y_pred_classes)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d')\n",
    "    plt.title('Confusion Matrix - Test Data Without Majority Voting)')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab9099a-cb95-4bd8-9010-497c6cd21b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result_without_MV(reposition_model_79,reposition_X_test,reposition_y_test)\n",
    "show_result_without_MV(contextmenu_model_85,contextmenu_X_test,contextmenu_y_test)\n",
    "show_result_without_MV(bikeyboard_model_91,bikeyboard_X_test,bikeyboard_y_test)\n",
    "show_result_without_MV(rescale_model_82,rescale_X_test,rescale_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "74820200-112d-4c0e-b116-559ed8faceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'reposition_uid_model.h5'\n",
    "reposition_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "431dafa9-ae1c-4667-8723-e4446a1cf441",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'contextmenu_uid_model.h5'\n",
    "contextmenu_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "6e14966d-8133-46e3-859e-2947199509e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'bikeyboard_uid_model.h5'\n",
    "bikeyboard_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0ee4bf27-c60a-4ac3-89db-175afaa68218",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = 'rescale_uid_model.h5'\n",
    "rescale_model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9d4af7b7-68da-45de-9e2d-c52b8792117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc2f27d-af88-4e35-b265-bab689a58cff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
